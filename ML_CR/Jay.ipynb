{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Downloading https://files.pythonhosted.org/packages/91/55/8cb23a97301b177e9c8e3226dba45bb454411de2cbd25746763267f226c2/tqdm-4.28.1-py2.py3-none-any.whl (45kB)\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.28.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed 1.21.8 requires msgpack, which is not installed.\n",
      "You are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm\n",
    "# import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm \n",
    "from collections import deque, defaultdict, Counter\n",
    "# import timeit\n",
    "# from sklearn.preprocessing import normalize\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "# from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cache Replacement Policy\n",
    "#### Read here for introduction: https://en.wikipedia.org/wiki/Cache_replacement_policies\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Blocktraces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132289"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = \"cheetah.cs.fiu.edu-110108-113008.1.blkparse\"\n",
    "\n",
    "df = pd.read_csv(train, sep=' ',header = None)\n",
    "df.columns = ['timestamp','pid','pname','blockNo', \\\n",
    "              'blockSize', 'readOrWrite', 'bdMajor', 'bdMinor', 'hash']\n",
    "\n",
    "trainBlockTrace = df['blockNo'].tolist()\n",
    "trainBlockTrace = trainBlockTrace[:int(len(trainBlockTrace)*0.1)]\n",
    "\n",
    "len(trainBlockTrace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Belady's Optimal Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def belady_opt(blocktrace, frame):\n",
    "    '''\n",
    "    INPUT\n",
    "    ==========\n",
    "    blocktrace = list of block request sequence\n",
    "    frame = size of the cache\n",
    "    \n",
    "    OUTPUT\n",
    "    ==========\n",
    "    hitrate \n",
    "    '''\n",
    "    infinite_index = 10000 * len(blocktrace) # should be a large integer\n",
    "    \n",
    "    block_index = defaultdict(deque) \n",
    "    # dictionary with block number as key and list\n",
    "    # of index value in blocktrace\n",
    "    \n",
    "    upcoming_index = defaultdict(int)\n",
    "    # dictionary with index number as key and value as block\n",
    "    \n",
    "    frequency = defaultdict(int)\n",
    "    # dictionary of block as key and number\n",
    "    # of times it's been requested so far\n",
    "    \n",
    "    recency = list()\n",
    "    # list of block in order of their request\n",
    "    \n",
    "    Cache = deque()\n",
    "    # Cache with block\n",
    "    \n",
    "    dataset = np.array([]).reshape(0,3*frame+1)\n",
    "    #columns represents the number of block in cache and \n",
    "    #3 is the number of features such as frequency, recency and block number\n",
    "    #+1 is for label 0-1\n",
    "    \n",
    "    hit, miss = 0, 0\n",
    "    \n",
    "    # populate the block_index\n",
    "    for i, block in enumerate(tqdm(blocktrace, \\\n",
    "                              desc=\"buidling index\", leave=False)):\n",
    "        block_index[block].append(i)\n",
    "        \n",
    "    # sequential block requests start\n",
    "    for i, block in enumerate(tqdm(blocktrace, desc=\"sequence\", leave=False)):\n",
    "        \n",
    "        # increament the frequency number for the block\n",
    "        frequency[block] += 1\n",
    "        \n",
    "        # make sure block has the value in block_index dictionary \n",
    "        # as current seq_number\n",
    "        if len(block_index[block]) != 0 and block_index[block][0] == i:\n",
    "            \n",
    "            # if yes, remove the first element of block_index[block]\n",
    "            block_index[block].popleft()\n",
    "        \n",
    "        # if block exist in current cache\n",
    "        if block in Cache:\n",
    "            \n",
    "            # increment hit\n",
    "            hit += 1\n",
    "            \n",
    "            # update the recency\n",
    "            recency.remove(block)\n",
    "            recency.append(block)\n",
    "            \n",
    "            # update upcoming_index\n",
    "            if i in upcoming_index:\n",
    "                \n",
    "                # delete old index\n",
    "                del upcoming_index[i]\n",
    "        \n",
    "                if len(block_index[block]) is not 0:\n",
    "                    # add new upcoming index\n",
    "                    upcoming_index[block_index[block][0]] = block\n",
    "                    # remove index from block_index\n",
    "                    block_index[block].popleft()\n",
    "                else:\n",
    "                    # add a large integer as index\n",
    "                    upcoming_index[infinite_index] = block\n",
    "                    # increament large integer\n",
    "                    infinite_index-=1\n",
    "           \n",
    "        # block not in current cache\n",
    "        else:\n",
    "            \n",
    "            # increament miss\n",
    "            miss += 1\n",
    "            \n",
    "            # if cache has no free space\n",
    "            if len(Cache) == frame:\n",
    "                \n",
    "                \n",
    "                # evict the farthest block in future request from cache\n",
    "                if len(upcoming_index) != 0:\n",
    "                    \n",
    "                    # find the farthest i.e. max_index in upcoming_index\n",
    "                    max_index = max(upcoming_index)\n",
    "                    \n",
    "                    # remove the block with max_index from cache\n",
    "                    Cache.remove(upcoming_index[max_index])\n",
    "                    \n",
    "                    # remove the block with max_index from recency dict\n",
    "                    recency.remove(upcoming_index[max_index])\n",
    "                    \n",
    "                    # remove max_index element from upcoming_index\n",
    "                    del upcoming_index[max_index]\n",
    "                    \n",
    "            # add upcoming request of current block in upcoming_index\n",
    "            if len(block_index[block]) != 0:\n",
    "                \n",
    "                # add upcoming index of block\n",
    "                upcoming_index[block_index[block][0]] = block\n",
    "               \n",
    "                # remove the index from block_index \n",
    "                block_index[block].popleft()\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                # add a large integer as index\n",
    "                upcoming_index[infinite_index] = block\n",
    "                \n",
    "                # increament high number\n",
    "                infinite_index -= 1\n",
    "                \n",
    "            \n",
    "            # add block into Cache\n",
    "            Cache.append(block)\n",
    "            \n",
    "            # add block into recency\n",
    "            recency.append(block)\n",
    "            \n",
    "            \n",
    "    # calculate hitrate\n",
    "    hitrate = hit / (hit + miss)\n",
    "\n",
    "    return hitrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='buidling index', max=132289, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='sequence', max=132289, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.014498559970972644"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "belady_opt(trainBlockTrace, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Least Frequently Used "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LFU(blocktrace, frame):\n",
    "    '''\n",
    "    INPUT\n",
    "    ==========\n",
    "    blocktrace = list of block request sequence\n",
    "    frame = size of the cache\n",
    "    \n",
    "    OUTPUT\n",
    "    ==========\n",
    "    hitrate \n",
    "    '''\n",
    "    \n",
    "    cache = set()\n",
    "    \n",
    "    cache_frequency = defaultdict(int)\n",
    "    \n",
    "    frequency = defaultdict(int)\n",
    "    \n",
    "    hit, miss = 0, 0\n",
    "    \n",
    "    for block in tqdm(blocktrace, leave=False):\n",
    "        frequency[block] += 1\n",
    "        \n",
    "        if block in cache:\n",
    "            hit += 1\n",
    "            cache_frequency[block] += 1\n",
    "        \n",
    "        elif len(cache) < frame:\n",
    "            cache.add(block)\n",
    "            cache_frequency[block] += 1\n",
    "            miss += 1\n",
    "\n",
    "        else:\n",
    "            e, f = min(cache_frequency.items(), key=lambda a: a[1])\n",
    "            cache_frequency.pop(e)\n",
    "            cache.remove(e)\n",
    "            cache.add(block)\n",
    "            cache_frequency[block] = frequency[block]\n",
    "            miss += 1\n",
    "    \n",
    "    hitrate = hit / ( hit + miss )\n",
    "    return hitrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=132289), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.011059120561800301"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFU(trainBlockTrace, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Least Recently Used (LRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LRU(blocktrace, frame):\n",
    "    '''\n",
    "    INPUT\n",
    "    ==========\n",
    "    blocktrace = list of block request sequence\n",
    "    frame = size of the cache\n",
    "    \n",
    "    OUTPUT\n",
    "    ==========\n",
    "    hitrate \n",
    "    '''\n",
    "    \n",
    "    cache = set()\n",
    "    \n",
    "    recency = deque()\n",
    "    \n",
    "    hit, miss = 0, 0\n",
    "    \n",
    "    for block in tqdm(blocktrace, leave=False):\n",
    "        \n",
    "        if block in cache:\n",
    "            recency.remove(block)\n",
    "            recency.append(block)\n",
    "            hit += 1\n",
    "            \n",
    "        elif len(cache) < frame:\n",
    "            cache.add(block)\n",
    "            recency.append(block)\n",
    "            miss += 1\n",
    "            \n",
    "        else:\n",
    "            cache.remove(recency[0])\n",
    "            recency.popleft()\n",
    "            cache.add(block)\n",
    "            recency.append(block)\n",
    "            miss += 1\n",
    "    \n",
    "    hitrate = hit / (hit + miss)\n",
    "    return hitrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=132289), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.009766496080550914"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LRU(trainBlockTrace, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to implement ML cache replacement policy?\n",
    "\n",
    "First, we need a base algorithm for our Machine Learning Model to learn. The obvious choice would be, the most desirable and otherwise practically impossible, Belady's Optimal algorithm. This is Supervised Learning approach.\n",
    "\n",
    "#### How to label data?\n",
    "\n",
    "There are two approaches for labelling the dataset of bloacktrace. Since the most usable properties of blocks are recency (e.g. in LRU) and frequency (e.g. in LFU), we generate these property by tracing the training data to generate 2 features. In total we have three properties: 1. BlockNumber 2. Recency (of Block request) 3. frequency (of Block request)\n",
    "\n",
    "Our data would be generated based on Belady's Optimal algorithm. The ML model we desire is predicting which block to evict from cache when miss occures. Therefore, we capture the cache configuration (cache configuration is nothing but an array of cache with elements being blocks themselves) at every time miss occures and label would be 0(for not evicted blocks) and 1(for evicted block). But the problem with this approach is that there is only 1 block with label 1 and remaining blocks are labelled 0. This would make ML model very bias towards 0 and it would never give prediction of label 1. (For example, for cache size 500, 499 block would get label 0 and only one block would have label 1 in dataset for single eviction event. Note that there should be enormous amount of eviction events to be given to ML model to train. Let's say we gave 100 eviction events to ML model, with total 100 (#eviction) x 500 (# cachesize) = 50000 Rows(=datapoints) where 499x100 = 49900 labels are 0 and 1x100 = 100 labels are 1.)\n",
    "\n",
    "To overcome the bayse error from our dataset, we impliment a interval approach in Belady's Optimal Algorithm. In this approach let's say we have interval of 100 eviction. When first miss occures, we will put x% of blocks into eviction candidates list (which we call buffer cache) and remove the first element that belady's algorithm selects. In next miss, we don't call belady's algorithm for next candidate but remove the second element from Buffer Cache. So we call belady's algorithm only once to get x% block from cache to put aside and consider as potential candidates of eviction, then remove one block at a time when miss occures. Once this buffer cache is empty we call Belady's Optimal algorithm again to get more x% block as next eviction candidates. This approach will ensure x% blocks with label of 1 and (1-x)% of blocks with label of 0.\n",
    "\n",
    "Next problem is the size of the dataset. Even if we capture the cache configuration with x% of 1s and (1-x)% of 0s everytime miss occures. The size of the dataset could be very large. So we decided to capture the cache configuration with a constant interval of y misses. For example, for a blocktrace of size more than 500k, the interval of 1k can reduce the dataset to feasible size. This reduction would actually helpful as there could be more than one instance of same blockNumber that occures in dataset with different labels(1 and 0) which could lead to ambiguous dataset.\n",
    "\n",
    "So, apart from cache size, there are paramters such as x(% of eviction candidates) and y(interval of capture the cache configuration) which needs to be optimized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
