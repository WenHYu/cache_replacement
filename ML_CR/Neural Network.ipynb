{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, deque, Counter\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm \n",
    "import pandas as pd\n",
    "\n",
    "#from sklearn.preprocessing import normalize\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1322890"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"cheetah.cs.fiu.edu-110108-113008.1.blkparse\"\n",
    "df = pd.read_csv(filename, sep=' ',header = None)\n",
    "df.columns = ['timestamp','pid','pname','blockNo', \\\n",
    "              'blockSize', 'readOrWrite', 'bdMajor', 'bdMinor', 'hash']\n",
    "blocktrace = df['blockNo'].tolist()\n",
    "len(blocktrace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def belady_opt(blocktrace, frame):\n",
    "    '''\n",
    "    INPUT\n",
    "    ==========\n",
    "    blocktrace = list of block request sequence\n",
    "    frame = size of the cache\n",
    "    \n",
    "    OUTPUT\n",
    "    ==========\n",
    "    hitrate \n",
    "    '''\n",
    "    infinite_index = 10000 * len(blocktrace) # should be a large integer\n",
    "    \n",
    "    block_index = defaultdict(deque) \n",
    "    # dictionary with block number as key and list\n",
    "    # of index value in blocktrace\n",
    "    \n",
    "    upcoming_index = defaultdict(int)\n",
    "    # dictionary with index number as key and value as block\n",
    "    \n",
    "    frequency = defaultdict(int)\n",
    "    # dictionary of block as key and number\n",
    "    # of times it's been requested so far\n",
    "    \n",
    "    recency = list()\n",
    "    # list of block in order of their request\n",
    "    \n",
    "    Cache = deque()\n",
    "    # Cache with block\n",
    "    \n",
    "    dataset = np.array([]).reshape(0,3*frame+1)\n",
    "    #columns represents the number of block in cache and \n",
    "    #3 is the number of features such as frequency, recency and block number\n",
    "    #+1 is for label 0-1\n",
    "    \n",
    "    hit, miss = 0, 0\n",
    "    \n",
    "    # populate the block_index\n",
    "    for i, block in enumerate(tqdm(blocktrace, \\\n",
    "                              desc=\"buidling index\", leave=False)):\n",
    "        block_index[block].append(i)\n",
    "        \n",
    "    # sequential block requests start\n",
    "    for i, block in enumerate(tqdm(blocktrace, desc=\"sequence\", leave=False)):\n",
    "        \n",
    "        # increament the frequency number for the block\n",
    "        frequency[block] += 1\n",
    "        \n",
    "        # make sure block has the value in block_index dictionary \n",
    "        # as current seq_number\n",
    "        if len(block_index[block]) != 0 and block_index[block][0] == i:\n",
    "            \n",
    "            # if yes, remove the first element of block_index[block]\n",
    "            block_index[block].popleft()\n",
    "        \n",
    "        # if block exist in current cache\n",
    "        if block in Cache:\n",
    "            \n",
    "            # increment hit\n",
    "            hit += 1\n",
    "            \n",
    "            # update the recency\n",
    "            recency.remove(block)\n",
    "            recency.append(block)\n",
    "            \n",
    "            # update upcoming_index\n",
    "            if i in upcoming_index:\n",
    "                \n",
    "                # delete old index\n",
    "                del upcoming_index[i]\n",
    "        \n",
    "                if len(block_index[block]) is not 0:\n",
    "                    # add new upcoming index\n",
    "                    upcoming_index[block_index[block][0]] = block\n",
    "                    # remove index from block_index\n",
    "                    block_index[block].popleft()\n",
    "                else:\n",
    "                    # add a large integer as index\n",
    "                    upcoming_index[infinite_index] = block\n",
    "                    # increament large integer\n",
    "                    infinite_index-=1\n",
    "           \n",
    "        # block not in current cache\n",
    "        else:\n",
    "            \n",
    "            # increament miss\n",
    "            miss += 1\n",
    "            \n",
    "            # if cache has no free space\n",
    "            if len(Cache) == frame:\n",
    "                \n",
    "                \n",
    "                # evict the farthest block in future request from cache\n",
    "                if len(upcoming_index) != 0:\n",
    "                    \n",
    "                    # find the farthest i.e. max_index in upcoming_index\n",
    "                    max_index = max(upcoming_index)\n",
    "                    \n",
    "                    if (i % 1000 +1 == 1000):\n",
    "                        blockNo = np.array([i for i in Cache])\n",
    "                        blockNo = blockNo / np.linalg.norm(blockNo)\n",
    "                        recency_ = np.array([recency.index(i) for i in Cache])\n",
    "                        recency_ = recency_ / np.linalg.norm(recency_)\n",
    "                        frequency_ = np.array([frequency[i] for i in Cache])\n",
    "                        frequency_ = frequency_ / np.linalg.norm(frequency_)\n",
    "                        stack = np.column_stack((blockNo, recency_, frequency_)).reshape(1,frame*3)\n",
    "                        \n",
    "                        stack = np.append(stack, Cache.index(upcoming_index[max_index]))\n",
    "                        dataset = np.vstack((dataset, stack))\n",
    "                    # remove the block with max_index from cache\n",
    "                    Cache.remove(upcoming_index[max_index])\n",
    "                    \n",
    "                    # remove the block with max_index from recency dict\n",
    "                    recency.remove(upcoming_index[max_index])\n",
    "                    \n",
    "                    # remove max_index element from upcoming_index\n",
    "                    del upcoming_index[max_index]\n",
    "                    \n",
    "            # add upcoming request of current block in upcoming_index\n",
    "            if len(block_index[block]) != 0:\n",
    "                \n",
    "                # add upcoming index of block\n",
    "                upcoming_index[block_index[block][0]] = block\n",
    "               \n",
    "                # remove the index from block_index \n",
    "                block_index[block].popleft()\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                # add a large integer as index\n",
    "                upcoming_index[infinite_index] = block\n",
    "                \n",
    "                # increament high number\n",
    "                infinite_index -= 1\n",
    "                \n",
    "                \n",
    "            \n",
    "            # add block into Cache\n",
    "            Cache.append(block)\n",
    "            \n",
    "            # add block into recency\n",
    "            recency.append(block)\n",
    "            \n",
    "            \n",
    "    # calculate hitrate\n",
    "    hitrate = hit / (hit + miss)\n",
    "\n",
    "    return hitrate, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='buidling index', max=1322890, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='sequence', max=1322890, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "hitrate, dataset = belady_opt(blocktrace, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0713407766329778"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hitrate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LRU for Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LRU(blocktrace, frame):\n",
    "    \n",
    "    cache = set()\n",
    "    recency = deque()\n",
    "    hit, miss = 0, 0\n",
    "    \n",
    "    for block in tqdm(blocktrace, leave=False):\n",
    "        \n",
    "        if block in cache:\n",
    "            recency.remove(block)\n",
    "            recency.append(block)\n",
    "            hit += 1\n",
    "            \n",
    "        elif len(cache) < frame:\n",
    "            cache.add(block)\n",
    "            recency.append(block)\n",
    "            miss += 1\n",
    "            \n",
    "        else:\n",
    "            cache.remove(recency[0])\n",
    "            recency.popleft()\n",
    "            cache.add(block)\n",
    "            recency.append(block)\n",
    "            miss += 1\n",
    "    \n",
    "    hitrate = hit / (hit + miss)\n",
    "    return hitrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0401"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LRU(blocktrace[:20000],1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.68679136e-02, 0.00000000e+00, 2.58371195e-02, ...,\n",
       "        5.47585541e-02, 2.58371195e-02, 1.10000000e+01],\n",
       "       [5.56609085e-02, 0.00000000e+00, 3.14347307e-02, ...,\n",
       "        5.47585541e-02, 3.14347307e-02, 1.23000000e+02],\n",
       "       [5.22193872e-02, 5.04831115e-02, 9.35219530e-02, ...,\n",
       "        5.47585541e-02, 3.11739843e-02, 2.81000000e+02],\n",
       "       ...,\n",
       "       [5.76438802e-02, 0.00000000e+00, 3.16104860e-02, ...,\n",
       "        5.47585541e-02, 3.16104860e-02, 0.00000000e+00],\n",
       "       [3.16207593e-02, 0.00000000e+00, 3.64071235e-02, ...,\n",
       "        5.47585541e-02, 2.42714157e-02, 0.00000000e+00],\n",
       "       [3.16187781e-02, 0.00000000e+00, 2.48778542e-02, ...,\n",
       "        5.47585541e-02, 1.24389271e-02, 0.00000000e+00]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1240, 3001)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.82\n",
      "[[  1   0   0 ...   0   0   7]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   1]\n",
      " ...\n",
      " [  0   0   0 ...  11   0   8]\n",
      " [  0   0   0 ...   0   5   2]\n",
      " [  1   0   0 ...   5   2 446]]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(dataset[:,:-1], dataset[:,-1].astype(int), test_size=0.3, random_state=None, shuffle=True)\n",
    "\n",
    "#Fitting Logistic Regression Model\n",
    "NN=MLPClassifier(solver='lbfgs', alpha=1e-5, random_state=42)\n",
    "NN.fit(X_train, Y_train)\n",
    "#NN.fit(dataset[:,:-1], dataset[:,-1].astype(int))\n",
    "\n",
    "Y_pred = NN.predict(X_test)\n",
    "\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(NN.score(X_test, Y_test)))\n",
    "\n",
    "print(confusion_matrix(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ourcacheNN(blocktrace,frame):\n",
    "    '''\n",
    "    INPUT\n",
    "    ==========\n",
    "    blocktrace = list of block request sequence\n",
    "    frame = size of the cache\n",
    "    \n",
    "    OUTPUT\n",
    "    ==========\n",
    "    hitrate \n",
    "    '''\n",
    "    #global sample_interval # interval of choice for sampling\n",
    "    infinite_index = 100 * len(blocktrace) # should be a large integer\n",
    "    \n",
    "    block_index = defaultdict(deque) \n",
    "    # dictionary with block number as key and list\n",
    "    # of index value in blocktrace\n",
    "    \n",
    "    upcoming_index = defaultdict(int)\n",
    "    # dictionary with index number as key and value as block\n",
    "    \n",
    "    frequency = defaultdict(int)\n",
    "    # dictionary of block as key and number\n",
    "    # of times it's been requested so far\n",
    "    \n",
    "    recency = list()\n",
    "    # list of block in order of their request\n",
    "    \n",
    "    Cache = deque()\n",
    "    # Cache with block\n",
    "    \n",
    "    hit, miss = 0, 0\n",
    "    \n",
    "    # populate the block_index\n",
    "    #for i, block in enumerate(tqdm(blocktrace, \\\n",
    "      #                        desc=\"buidling index\", leave=False)):\n",
    "     #   block_index[block].append(i)\n",
    "        \n",
    "    # sequential block requests start\n",
    "    for i, block in enumerate(tqdm(blocktrace, desc=\"sequence\", leave=False)):\n",
    "        \n",
    "        # increament the frequency number for the block\n",
    "        frequency[block] += 1\n",
    "        \n",
    "        # make sure block has the value in block_index dictionary \n",
    "        # as current seq_number\n",
    "        #if len(block_index[block]) != 0 and block_index[block][0] == i:\n",
    "            \n",
    "            # if yes, remove the first element of block_index[block]\n",
    "        #    block_index[block].popleft()\n",
    "        \n",
    "        # if block exist in current cache\n",
    "        if block in Cache:\n",
    "            \n",
    "            # increment hit\n",
    "            hit += 1\n",
    "            \n",
    "            # update the recency\n",
    "            recency.remove(block)\n",
    "            recency.append(block)\n",
    "            \n",
    "            # update upcoming_index\n",
    "            #if i in upcoming_index:\n",
    "                \n",
    "                # delete old index\n",
    "             #   del upcoming_index[i]\n",
    "        \n",
    "              #  if len(block_index[block]) is not 0:\n",
    "                    # add new upcoming index\n",
    "               #     upcoming_index[block_index[block][0]] = block\n",
    "                    # remove index from block_index\n",
    "                #    block_index[block].popleft()\n",
    "#                 else:\n",
    "#                     # add a large integer as index\n",
    "#                     upcoming_index[infinite_index] = block\n",
    "#                     # increament large integer\n",
    "#                     infinite_index+=1\n",
    "           \n",
    "        # block not in current cache\n",
    "        else:\n",
    "            \n",
    "            # increament miss\n",
    "            miss += 1\n",
    "            \n",
    "            # if cache has no free space\n",
    "            if len(Cache) == frame:\n",
    "                blockNo = np.array([i for i in Cache])\n",
    "                blockNo = blockNo / np.linalg.norm(blockNo)\n",
    "                recency_ = np.array([recency.index(i) for i in Cache])\n",
    "                recency_ = recency_ / np.linalg.norm(recency_)\n",
    "                frequency_ = np.array([frequency[i] for i in Cache])\n",
    "                frequency_ = frequency_ / np.linalg.norm(frequency_)\n",
    "                stack = np.column_stack((blockNo, recency_, frequency_)).reshape(1,frame*3)\n",
    "                X_current = NN.predict(stack)\n",
    "#                 return X_current\n",
    "                Cache.remove(Cache[X_current[0]])\n",
    "                \n",
    "                # evict the farthest block in future request from cache\n",
    "#                 if len(upcoming_index) != 0:\n",
    "                    \n",
    "#                     # find the farthest i.e. max_index in upcoming_index\n",
    "#                     max_index = max(upcoming_index)\n",
    "                    \n",
    "#                     # remove the block with max_index from cache\n",
    "#                     Cache.remove(upcoming_index[max_index])\n",
    "                    \n",
    "#                     # remove the block with max_index from recency dict\n",
    "#                     recency.remove(upcoming_index[max_index])\n",
    "                    \n",
    "#                     # remove max_index element from upcoming_index\n",
    "#                     del upcoming_index[max_index]\n",
    "                    \n",
    "            # add upcoming request of current block in upcoming_index\n",
    "#             if len(block_index[block]) != 0:\n",
    "                \n",
    "#                 # add upcoming index of block\n",
    "#                 upcoming_index[block_index[block][0]] = block\n",
    "               \n",
    "#                 # remove the index from block_index \n",
    "#                 block_index[block].popleft()\n",
    "            \n",
    "#             else:\n",
    "                \n",
    "#                 # add a large integer as index\n",
    "#                 upcoming_index[infinite_index] = block\n",
    "                \n",
    "#                 # increament high number\n",
    "#                 infinite_index += 1\n",
    "                \n",
    "            \n",
    "            # add block into Cache\n",
    "            Cache.append(block)\n",
    "            \n",
    "            # add block into recency\n",
    "            recency.append(block)\n",
    "            \n",
    "            #### regression extra part\n",
    "#             if (i % sample_interval +1 == sample_interval):\n",
    "#                 Y_OPT = populateData(frequency, recency, Cache, block_index)\n",
    "#                 lruPredict(Cache,recency,Y_OPT)\n",
    "#                 lfuPredict(Cache,frequency,Y_OPT)\n",
    "            \n",
    "    # calculate hitrate\n",
    "    hitrate = hit / (hit + miss)\n",
    "\n",
    "    return hitrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='sequence', max=20000, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0334"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ourcacheNN(blocktrace[:20000],1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.68679136e-02, 0.00000000e+00, 2.58371195e-02, ...,\n",
       "        5.47585541e-02, 2.58371195e-02, 1.10000000e+01],\n",
       "       [5.56609085e-02, 0.00000000e+00, 3.14347307e-02, ...,\n",
       "        5.47585541e-02, 3.14347307e-02, 1.23000000e+02],\n",
       "       [5.22193872e-02, 5.04831115e-02, 9.35219530e-02, ...,\n",
       "        5.47585541e-02, 3.11739843e-02, 2.81000000e+02],\n",
       "       ...,\n",
       "       [5.76438802e-02, 0.00000000e+00, 3.16104860e-02, ...,\n",
       "        5.47585541e-02, 3.16104860e-02, 0.00000000e+00],\n",
       "       [3.16207593e-02, 0.00000000e+00, 3.64071235e-02, ...,\n",
       "        5.47585541e-02, 2.42714157e-02, 0.00000000e+00],\n",
       "       [3.16187781e-02, 0.00000000e+00, 2.48778542e-02, ...,\n",
       "        5.47585541e-02, 1.24389271e-02, 0.00000000e+00]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1240, 3001)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.84\n",
      "[[  3   0   0 ...   0   0   4]\n",
      " [  0   0   0 ...   0   0   1]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   9   0   0]\n",
      " [  0   0   0 ...   0   3   1]\n",
      " [  2   0   0 ...   2   2 269]]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(dataset[:,:-1], dataset[:,-1].astype(int), test_size=0.3, random_state=None, shuffle=True)\n",
    "\n",
    "#Fitting Logistic Regression Model\n",
    "NN=MLPClassifier(solver='lbfgs', alpha=1e-5, random_state=42)\n",
    "NN.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = NN.predict(X_test)\n",
    "\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(NN.score(X_test, Y_test)))\n",
    "\n",
    "print(confusion_matrix(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ourcacheNN(blocktrace,frame):\n",
    "    '''\n",
    "    INPUT\n",
    "    ==========\n",
    "    blocktrace = list of block request sequence\n",
    "    frame = size of the cache\n",
    "    \n",
    "    OUTPUT\n",
    "    ==========\n",
    "    hitrate \n",
    "    '''\n",
    "    #global sample_interval # interval of choice for sampling\n",
    "    infinite_index = 100 * len(blocktrace) # should be a large integer\n",
    "    \n",
    "    block_index = defaultdict(deque) \n",
    "    # dictionary with block number as key and list\n",
    "    # of index value in blocktrace\n",
    "    \n",
    "    upcoming_index = defaultdict(int)\n",
    "    # dictionary with index number as key and value as block\n",
    "    \n",
    "    frequency = defaultdict(int)\n",
    "    # dictionary of block as key and number\n",
    "    # of times it's been requested so far\n",
    "    \n",
    "    recency = list()\n",
    "    # list of block in order of their request\n",
    "    \n",
    "    Cache = deque()\n",
    "    # Cache with block\n",
    "    \n",
    "    hit, miss = 0, 0\n",
    "    \n",
    "    # populate the block_index\n",
    "    #for i, block in enumerate(tqdm(blocktrace, \\\n",
    "      #                        desc=\"buidling index\", leave=False)):\n",
    "     #   block_index[block].append(i)\n",
    "        \n",
    "    # sequential block requests start\n",
    "    for i, block in enumerate(tqdm(blocktrace, desc=\"sequence\", leave=False)):\n",
    "        \n",
    "        # increament the frequency number for the block\n",
    "        frequency[block] += 1\n",
    "        \n",
    "        # make sure block has the value in block_index dictionary \n",
    "        # as current seq_number\n",
    "        #if len(block_index[block]) != 0 and block_index[block][0] == i:\n",
    "            \n",
    "            # if yes, remove the first element of block_index[block]\n",
    "        #    block_index[block].popleft()\n",
    "        \n",
    "        # if block exist in current cache\n",
    "        if block in Cache:\n",
    "            \n",
    "            # increment hit\n",
    "            hit += 1\n",
    "            \n",
    "            # update the recency\n",
    "            recency.remove(block)\n",
    "            recency.append(block)\n",
    "            \n",
    "            # update upcoming_index\n",
    "            #if i in upcoming_index:\n",
    "                \n",
    "                # delete old index\n",
    "             #   del upcoming_index[i]\n",
    "        \n",
    "              #  if len(block_index[block]) is not 0:\n",
    "                    # add new upcoming index\n",
    "               #     upcoming_index[block_index[block][0]] = block\n",
    "                    # remove index from block_index\n",
    "                #    block_index[block].popleft()\n",
    "#                 else:\n",
    "#                     # add a large integer as index\n",
    "#                     upcoming_index[infinite_index] = block\n",
    "#                     # increament large integer\n",
    "#                     infinite_index+=1\n",
    "           \n",
    "        # block not in current cache\n",
    "        else:\n",
    "            \n",
    "            # increament miss\n",
    "            miss += 1\n",
    "            \n",
    "            # if cache has no free space\n",
    "            if len(Cache) == frame:\n",
    "                blockNo = np.array([i for i in Cache])\n",
    "                blockNo = blockNo / np.linalg.norm(blockNo)\n",
    "                recency_ = np.array([recency.index(i) for i in Cache])\n",
    "                recency_ = recency_ / np.linalg.norm(recency_)\n",
    "                frequency_ = np.array([frequency[i] for i in Cache])\n",
    "                frequency_ = frequency_ / np.linalg.norm(frequency_)\n",
    "                stack = np.column_stack((blockNo, recency_, frequency_)).reshape(1,frame*3)\n",
    "                X_current = NN.predict(stack)\n",
    "#                 return X_current\n",
    "                Cache.remove(Cache[X_current[0]])\n",
    "                \n",
    "                # evict the farthest block in future request from cache\n",
    "#                 if len(upcoming_index) != 0:\n",
    "                    \n",
    "#                     # find the farthest i.e. max_index in upcoming_index\n",
    "#                     max_index = max(upcoming_index)\n",
    "                    \n",
    "#                     # remove the block with max_index from cache\n",
    "#                     Cache.remove(upcoming_index[max_index])\n",
    "                    \n",
    "#                     # remove the block with max_index from recency dict\n",
    "#                     recency.remove(upcoming_index[max_index])\n",
    "                    \n",
    "#                     # remove max_index element from upcoming_index\n",
    "#                     del upcoming_index[max_index]\n",
    "                    \n",
    "            # add upcoming request of current block in upcoming_index\n",
    "#             if len(block_index[block]) != 0:\n",
    "                \n",
    "#                 # add upcoming index of block\n",
    "#                 upcoming_index[block_index[block][0]] = block\n",
    "               \n",
    "#                 # remove the index from block_index \n",
    "#                 block_index[block].popleft()\n",
    "            \n",
    "#             else:\n",
    "                \n",
    "#                 # add a large integer as index\n",
    "#                 upcoming_index[infinite_index] = block\n",
    "                \n",
    "#                 # increament high number\n",
    "#                 infinite_index += 1\n",
    "                \n",
    "            \n",
    "            # add block into Cache\n",
    "            Cache.append(block)\n",
    "            \n",
    "            # add block into recency\n",
    "            recency.append(block)\n",
    "            \n",
    "            #### regression extra part\n",
    "#             if (i % sample_interval +1 == sample_interval):\n",
    "#                 Y_OPT = populateData(frequency, recency, Cache, block_index)\n",
    "#                 lruPredict(Cache,recency,Y_OPT)\n",
    "#                 lfuPredict(Cache,frequency,Y_OPT)\n",
    "            \n",
    "    # calculate hitrate\n",
    "    hitrate = hit / (hit + miss)\n",
    "\n",
    "    return hitrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='sequence', max=20000, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.03845"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ourcacheNN(blocktrace[:20000],1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create logistic regression\n",
    "logistic = linear_model.LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create regularization penalty space\n",
    "penalty = ['l1', 'l2']\n",
    "\n",
    "# Create regularization hyperparameter space\n",
    "C = np.logspace(0, 4, 10)\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(C=C, penalty=penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00000000e+00, 2.78255940e+00, 7.74263683e+00, 2.15443469e+01,\n",
       "       5.99484250e+01, 1.66810054e+02, 4.64158883e+02, 1.29154967e+03,\n",
       "       3.59381366e+03, 1.00000000e+04])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': array([1.00000e+00, 2.78256e+00, 7.74264e+00, 2.15443e+01, 5.99484e+01,\n",
       "       1.66810e+02, 4.64159e+02, 1.29155e+03, 3.59381e+03, 1.00000e+04]), 'penalty': ['l1', 'l2']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create grid search using 5-fold cross validation\n",
    "log_tun = GridSearchCV(logistic, hyperparameters, cv=5)\n",
    "log_tun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    }
   ],
   "source": [
    "# Fit grid search\n",
    "log_best = log_tun.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def our_cache_tuned(blocktrace,frame):\n",
    "    '''\n",
    "    INPUT\n",
    "    ==========\n",
    "    blocktrace = list of block request sequence\n",
    "    frame = size of the cache\n",
    "    \n",
    "    OUTPUT\n",
    "    ==========\n",
    "    hitrate \n",
    "    '''\n",
    "    #global sample_interval # interval of choice for sampling\n",
    "    infinite_index = 100 * len(blocktrace) # should be a large integer\n",
    "    \n",
    "    block_index = defaultdict(deque) \n",
    "    # dictionary with block number as key and list\n",
    "    # of index value in blocktrace\n",
    "    \n",
    "    upcoming_index = defaultdict(int)\n",
    "    # dictionary with index number as key and value as block\n",
    "    \n",
    "    frequency = defaultdict(int)\n",
    "    # dictionary of block as key and number\n",
    "    # of times it's been requested so far\n",
    "    \n",
    "    recency = list()\n",
    "    # list of block in order of their request\n",
    "    \n",
    "    Cache = deque()\n",
    "    # Cache with block\n",
    "    \n",
    "    hit, miss = 0, 0\n",
    "    \n",
    "    # populate the block_index\n",
    "    #for i, block in enumerate(tqdm(blocktrace, \\\n",
    "      #                        desc=\"buidling index\", leave=False)):\n",
    "     #   block_index[block].append(i)\n",
    "        \n",
    "    # sequential block requests start\n",
    "    for i, block in enumerate(tqdm(blocktrace, desc=\"sequence\", leave=False)):\n",
    "        \n",
    "        # increament the frequency number for the block\n",
    "        frequency[block] += 1\n",
    "        \n",
    "        # make sure block has the value in block_index dictionary \n",
    "        # as current seq_number\n",
    "        #if len(block_index[block]) != 0 and block_index[block][0] == i:\n",
    "            \n",
    "            # if yes, remove the first element of block_index[block]\n",
    "        #    block_index[block].popleft()\n",
    "        \n",
    "        # if block exist in current cache\n",
    "        if block in Cache:\n",
    "            \n",
    "            # increment hit\n",
    "            hit += 1\n",
    "            \n",
    "            # update the recency\n",
    "            recency.remove(block)\n",
    "            recency.append(block)\n",
    "            \n",
    "            # update upcoming_index\n",
    "            #if i in upcoming_index:\n",
    "                \n",
    "                # delete old index\n",
    "             #   del upcoming_index[i]\n",
    "        \n",
    "              #  if len(block_index[block]) is not 0:\n",
    "                    # add new upcoming index\n",
    "               #     upcoming_index[block_index[block][0]] = block\n",
    "                    # remove index from block_index\n",
    "                #    block_index[block].popleft()\n",
    "#                 else:\n",
    "#                     # add a large integer as index\n",
    "#                     upcoming_index[infinite_index] = block\n",
    "#                     # increament large integer\n",
    "#                     infinite_index+=1\n",
    "           \n",
    "        # block not in current cache\n",
    "        else:\n",
    "            \n",
    "            # increament miss\n",
    "            miss += 1\n",
    "            \n",
    "            # if cache has no free space\n",
    "            if len(Cache) == frame:\n",
    "                blockNo = np.array([i for i in Cache])\n",
    "                blockNo = blockNo / np.linalg.norm(blockNo)\n",
    "                recency_ = np.array([recency.index(i) for i in Cache])\n",
    "                recency_ = recency_ / np.linalg.norm(recency_)\n",
    "                frequency_ = np.array([frequency[i] for i in Cache])\n",
    "                frequency_ = frequency_ / np.linalg.norm(frequency_)\n",
    "                stack = np.column_stack((blockNo, recency_, frequency_)).reshape(1,frame*3)\n",
    "                X_current = log_best.predict(stack)\n",
    "#                 return X_current\n",
    "                Cache.remove(Cache[X_current[0]])\n",
    "                \n",
    "                # evict the farthest block in future request from cache\n",
    "#                 if len(upcoming_index) != 0:\n",
    "                    \n",
    "#                     # find the farthest i.e. max_index in upcoming_index\n",
    "#                     max_index = max(upcoming_index)\n",
    "                    \n",
    "#                     # remove the block with max_index from cache\n",
    "#                     Cache.remove(upcoming_index[max_index])\n",
    "                    \n",
    "#                     # remove the block with max_index from recency dict\n",
    "#                     recency.remove(upcoming_index[max_index])\n",
    "                    \n",
    "#                     # remove max_index element from upcoming_index\n",
    "#                     del upcoming_index[max_index]\n",
    "                    \n",
    "            # add upcoming request of current block in upcoming_index\n",
    "#             if len(block_index[block]) != 0:\n",
    "                \n",
    "#                 # add upcoming index of block\n",
    "#                 upcoming_index[block_index[block][0]] = block\n",
    "               \n",
    "#                 # remove the index from block_index \n",
    "#                 block_index[block].popleft()\n",
    "            \n",
    "#             else:\n",
    "                \n",
    "#                 # add a large integer as index\n",
    "#                 upcoming_index[infinite_index] = block\n",
    "                \n",
    "#                 # increament high number\n",
    "#                 infinite_index += 1\n",
    "                \n",
    "            \n",
    "            # add block into Cache\n",
    "            Cache.append(block)\n",
    "            \n",
    "            # add block into recency\n",
    "            recency.append(block)\n",
    "            \n",
    "            #### regression extra part\n",
    "#             if (i % sample_interval +1 == sample_interval):\n",
    "#                 Y_OPT = populateData(frequency, recency, Cache, block_index)\n",
    "#                 lruPredict(Cache,recency,Y_OPT)\n",
    "#                 lfuPredict(Cache,frequency,Y_OPT)\n",
    "            \n",
    "    # calculate hitrate\n",
    "    hitrate = hit / (hit + miss)\n",
    "\n",
    "    return hitrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='sequence', max=20000, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.03525"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_cache_tuned(blocktrace[:20000],1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Penalty: l1\n",
      "Best C: 166.81005372000593\n"
     ]
    }
   ],
   "source": [
    "# View best hyperparameters\n",
    "print('Best Penalty:', log_best.best_estimator_.get_params()['penalty'])\n",
    "print('Best C:', log_best.best_estimator_.get_params()['C'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
