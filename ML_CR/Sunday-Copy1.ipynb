{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (4.28.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed 1.21.8 requires msgpack, which is not installed.\n",
      "You are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm \n",
    "from collections import defaultdict, deque, Counter\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Blocktrace Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1322890"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"cheetah.cs.fiu.edu-110108-113008.1.blkparse\"\n",
    "\n",
    "df = pd.read_csv(filename, sep=' ',header = None)\n",
    "df.columns = ['timestamp','pid','pname','blockNo', \\\n",
    "              'blockSize', 'readOrWrite', 'bdMajor', 'bdMinor', 'hash']\n",
    "\n",
    "blocktrace = df['blockNo'].tolist()\n",
    "\n",
    "len(blocktrace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Belady's Optimal Algorithm (OPT) - 1\n",
    "\n",
    "Belady Algorithm given below, returns the hitrate and dataset. Dataset is (Cachesize*3) + 1 column long. Every 3 columns represents the blockNumber, Recency, Frequency. The Last column of the dataset is the INDEX of cache from which the block got evicted when new block is requested. The last column is therefore, a target colunm for Machie Learning, which represent single class at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def belady_opt_1(blocktrace, frame):\n",
    "    '''\n",
    "    INPUT\n",
    "    ============\n",
    "    blocktrace - list of blocks in sequence of request\n",
    "    cachesize - int value for capacity of the cache\n",
    "    \n",
    "    OUTPUT\n",
    "    ============\n",
    "    (1) hitrate (int)\n",
    "    (2) cache configuration and eviction block at time of miss (np.array)  \n",
    "    '''\n",
    "    \n",
    "    infinite_index = 100 * len(blocktrace) \n",
    "    # should be a large integer than block number\n",
    "    \n",
    "    block_index = defaultdict(deque) \n",
    "    # dictionary with block number as key and list\n",
    "    # of index value in blocktrace\n",
    "    \n",
    "    upcoming_index = defaultdict(int)\n",
    "    # dictionary with index number as key and value as block\n",
    "    \n",
    "    frequency = defaultdict(int)\n",
    "    # dictionary of block as key and number\n",
    "    # of times it's been requested so far\n",
    "    \n",
    "    recency = list()\n",
    "    # list of block in order of their request\n",
    "    \n",
    "    Cache = deque()\n",
    "    # Cache with block\n",
    "    \n",
    "    dataset = np.array([]).reshape(0,3*frame+1)\n",
    "    #columns represents the number of block in cache and \n",
    "    #3 is the number of features such as frequency, recency and block number\n",
    "    #+1 is for label 0-1\n",
    "    \n",
    "    hit, miss = 0, 0\n",
    "    \n",
    "    # populate the block_index\n",
    "    for i, block in enumerate(tqdm(blocktrace, \\\n",
    "                              desc=\"buidling index\", leave=False)):\n",
    "        block_index[block].append(i)\n",
    "        \n",
    "    # sequential block requests start\n",
    "    for i, block in enumerate(tqdm(blocktrace, desc=\"sequence\", leave=False)):\n",
    "        \n",
    "        # increament the frequency number for the block\n",
    "        frequency[block] += 1\n",
    "        \n",
    "        # make sure block has the value in block_index dictionary \n",
    "        # as current seq_number\n",
    "        if len(block_index[block]) != 0 and block_index[block][0] == i:\n",
    "            \n",
    "            # if yes, remove the first element of block_index[block]\n",
    "            block_index[block].popleft()\n",
    "        \n",
    "        # if block exist in current cache\n",
    "        if block in Cache:\n",
    "            \n",
    "            # increment hit\n",
    "            hit += 1\n",
    "            \n",
    "            # update the recency\n",
    "            recency.remove(block)\n",
    "            recency.append(block)\n",
    "            \n",
    "            # update upcoming_index\n",
    "            if i in upcoming_index:\n",
    "                \n",
    "                # delete old index\n",
    "                del upcoming_index[i]\n",
    "        \n",
    "                if len(block_index[block]) is not 0:\n",
    "                    # add new upcoming index\n",
    "                    upcoming_index[block_index[block][0]] = block\n",
    "                    # remove index from block_index\n",
    "                    block_index[block].popleft()\n",
    "                else:\n",
    "                    # add a large integer as index\n",
    "                    upcoming_index[infinite_index] = block\n",
    "                    # increament large integer\n",
    "                    infinite_index-=1\n",
    "           \n",
    "        # block not in current cache\n",
    "        else:\n",
    "            \n",
    "            # increament miss\n",
    "            miss += 1\n",
    "            \n",
    "            # if cache has no free space\n",
    "            if len(Cache) == frame:\n",
    "                  \n",
    "                # find the farthest i.e. max_index in upcoming_index\n",
    "                max_index = max(upcoming_index)\n",
    "\n",
    "                if (i % 1000 +1 == 1000):\n",
    "                    blockNo = np.array([i for i in Cache])\n",
    "                    blockNo = blockNo / np.linalg.norm(blockNo)\n",
    "                    recency_ = np.array([recency.index(i) for i in Cache])\n",
    "                    recency_ = recency_ / np.linalg.norm(recency_)\n",
    "                    frequency_ = np.array([frequency[i] for i in Cache])\n",
    "                    frequency_ = frequency_ / np.linalg.norm(frequency_)\n",
    "                    stack = np.column_stack((blockNo, recency_, frequency_)).reshape(1,frame*3)\n",
    "                    stack = np.append(stack, Cache.index(upcoming_index[max_index]))\n",
    "                    dataset = np.vstack((dataset, stack))\n",
    "                # remove the block with max_index from cache\n",
    "                Cache[Cache.index(upcoming_index[max_index])] = block\n",
    "\n",
    "                # remove the block with max_index from recency dict\n",
    "                recency.remove(upcoming_index[max_index])\n",
    "\n",
    "                # remove max_index element from upcoming_index\n",
    "                del upcoming_index[max_index]\n",
    "                    \n",
    "            \n",
    "            else:\n",
    "                 \n",
    "                # add block into Cache\n",
    "                Cache.append(block)\n",
    "\n",
    "            # add block into recency\n",
    "            recency.append(block)\n",
    "                \n",
    "            # add upcoming request of current block in upcoming_index\n",
    "            if len(block_index[block]) != 0:\n",
    "                \n",
    "                # add upcoming index of block\n",
    "                upcoming_index[block_index[block][0]] = block\n",
    "               \n",
    "                # remove the index from block_index \n",
    "                block_index[block].popleft()\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                # add a large integer as index\n",
    "                upcoming_index[infinite_index] = block\n",
    "                \n",
    "                # increament high number\n",
    "                infinite_index -= 1\n",
    " \n",
    "            \n",
    "    # calculate hitrate\n",
    "    hitrate = hit / (hit + miss)\n",
    "\n",
    "    return hitrate, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='buidling index', max=1322890, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='sequence', max=1322890, style=ProgressStyle(description_widthâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "hitrate, dataset= belady_opt_1(blocktrace, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0713407766329778"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hitrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.68679136e-02, 0.00000000e+00, 2.58371195e-02, ...,\n",
       "        3.19013799e-02, 2.58371195e-02, 4.28000000e+02],\n",
       "       [5.56609085e-02, 0.00000000e+00, 3.14347307e-02, ...,\n",
       "        2.66941100e-02, 3.14347307e-02, 5.48000000e+02],\n",
       "       [5.22193872e-02, 5.04831115e-02, 9.35219530e-02, ...,\n",
       "        1.88557984e-02, 3.11739843e-02, 8.90000000e+02],\n",
       "       ...,\n",
       "       [5.76442406e-02, 1.22781943e-02, 3.16104860e-02, ...,\n",
       "        5.38267269e-02, 3.16104860e-02, 7.89000000e+02],\n",
       "       [3.16216295e-02, 1.22781943e-02, 3.64071235e-02, ...,\n",
       "        5.38267269e-02, 2.42714157e-02, 7.89000000e+02],\n",
       "       [3.16196312e-02, 1.22781943e-02, 2.48778542e-02, ...,\n",
       "        5.38267269e-02, 1.24389271e-02, 7.89000000e+02]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([789])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.predict([dataset[1][:-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(dataset[:,:-1], dataset[:,-1].astype(int), test_size=0.3, \\\n",
    "                                                    random_state=None, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29838709677419356\n",
      "[[3 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 4 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, Y_train)\n",
    "\n",
    "print(logreg.score(X_test, Y_test))\n",
    "\n",
    "print(confusion_matrix(Y_test,logreg.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46774193548387094\n",
      "[[3 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 4 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "NN = MLPClassifier()\n",
    "NN.fit(X_train, Y_train)\n",
    "\n",
    "print(NN.score(X_test, Y_test))\n",
    "\n",
    "print(confusion_matrix(Y_test,NN.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Hitrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ML_policy_1(blocktrace,frame, model):\n",
    "    '''\n",
    "    INPUT\n",
    "    ==========\n",
    "    blocktrace = list of block request sequence\n",
    "    frame = size of the cache\n",
    "    model = trained ML model\n",
    "    \n",
    "    OUTPUT\n",
    "    ==========\n",
    "    hitrate \n",
    "    '''\n",
    "    #global sample_interval # interval of choice for sampling\n",
    "    infinite_index = 100 * len(blocktrace) # should be a large integer\n",
    "    \n",
    "    block_index = defaultdict(deque) \n",
    "    # dictionary with block number as key and list\n",
    "    # of index value in blocktrace\n",
    "    \n",
    "    upcoming_index = defaultdict(int)\n",
    "    # dictionary with index number as key and value as block\n",
    "    \n",
    "    frequency = defaultdict(int)\n",
    "    # dictionary of block as key and number\n",
    "    # of times it's been requested so far\n",
    "    \n",
    "    recency = list()\n",
    "    # list of block in order of their request\n",
    "    \n",
    "    Cache = deque()\n",
    "    # Cache with block\n",
    "    \n",
    "    hit, miss = 0, 0\n",
    "    \n",
    "    # populate the block_index\n",
    "    #for i, block in enumerate(tqdm(blocktrace, \\\n",
    "      #                        desc=\"buidling index\", leave=False)):\n",
    "     #   block_index[block].append(i)\n",
    "        \n",
    "    # sequential block requests start\n",
    "    for i, block in enumerate(tqdm(blocktrace, desc=\"sequence\", leave=False)):\n",
    "        \n",
    "        # increament the frequency number for the block\n",
    "        frequency[block] += 1\n",
    "        \n",
    "        # make sure block has the value in block_index dictionary \n",
    "        # as current seq_number\n",
    "        #if len(block_index[block]) != 0 and block_index[block][0] == i:\n",
    "            \n",
    "            # if yes, remove the first element of block_index[block]\n",
    "        #    block_index[block].popleft()\n",
    "        \n",
    "        # if block exist in current cache\n",
    "        if block in Cache:\n",
    "            \n",
    "            # increment hit\n",
    "            hit += 1\n",
    "            \n",
    "            # update the recency\n",
    "            recency.remove(block)\n",
    "            recency.append(block)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            # increament miss\n",
    "            miss += 1\n",
    "            \n",
    "            # if cache has no free space\n",
    "            if len(Cache) == frame:\n",
    "                blockNo = np.array([i for i in Cache])\n",
    "                blockNo = blockNo / np.linalg.norm(blockNo)\n",
    "                recency_ = np.array([recency.index(i) for i in Cache])\n",
    "                recency_ = recency_ / np.linalg.norm(recency_)\n",
    "                frequency_ = np.array([frequency[i] for i in Cache])\n",
    "                frequency_ = frequency_ / np.linalg.norm(frequency_)\n",
    "                stack = np.column_stack((blockNo, recency_, frequency_)).reshape(1,frame*3)\n",
    "                X_current = model.predict(stack)\n",
    "                \n",
    "                Cache[X_current[0]] = block\n",
    "                \n",
    "                \n",
    "            else:\n",
    "                # add block into Cache\n",
    "                Cache.append(block)\n",
    "\n",
    "            # add block into recency\n",
    "            recency.append(block)\n",
    "\n",
    "\n",
    "    # calculate hitrate\n",
    "    hitrate = hit / (hit + miss)\n",
    "\n",
    "    return hitrate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Belady's Optimal Algorithm (OPT) - 2\n",
    "\n",
    "Belady Algorithm given below, returns the hitrate and dataset. Dataset is [(Cachesize*3) + CacheSize] column long. Every 3 columns represents the blockNumber, Recency, Frequency. The Last column of the dataset is the a numpy 1d array of length same as Cache length. It repreent a binary array where the x% of element get 1 that are likely to be evicted and remaining get 0 that are not being evicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def belady_opt_2(blocktrace, frame, perc):\n",
    "    '''\n",
    "    INPUT\n",
    "    ============\n",
    "    blocktrace - list of blocks in sequence of request\n",
    "    cachesize - int value for capacity of the cache\n",
    "    perc - percentage of blocks that get 1(i.e. likely to be evicted) in numpy array of label\n",
    "    \n",
    "    OUTPUT\n",
    "    ============\n",
    "    (1) hitrate (int)\n",
    "    (2) cache configuration and eviction block at time of miss (np.array)  \n",
    "    '''\n",
    "    \n",
    "    infinite_index = 100 * len(blocktrace) \n",
    "    # should be a large integer than block number\n",
    "    \n",
    "    block_index = defaultdict(deque) \n",
    "    # dictionary with block number as key and list\n",
    "    # of index value in blocktrace\n",
    "    \n",
    "    upcoming_index = defaultdict(int)\n",
    "    # dictionary with index number as key and value as block\n",
    "    \n",
    "    frequency = defaultdict(int)\n",
    "    # dictionary of block as key and number\n",
    "    # of times it's been requested so far\n",
    "    \n",
    "    recency = list()\n",
    "    # list of block in order of their request\n",
    "    \n",
    "    Cache = deque()\n",
    "    # Cache with block\n",
    "    \n",
    "    dataset = np.array([]).reshape(0,(3*frame)+frame)\n",
    "    #columns represents the number of block in cache and \n",
    "    #3 is the number of features such as frequency, recency and block number\n",
    "    #+1 is for label 0-1\n",
    "    \n",
    "    hit, miss = 0, 0\n",
    "    \n",
    "    # populate the block_index\n",
    "    for i, block in enumerate(tqdm(blocktrace, \\\n",
    "                              desc=\"buidling index\", leave=False)):\n",
    "        block_index[block].append(i)\n",
    "        \n",
    "    # sequential block requests start\n",
    "    for i, block in enumerate(tqdm(blocktrace, desc=\"sequence\", leave=False)):\n",
    "        \n",
    "        # increament the frequency number for the block\n",
    "        frequency[block] += 1\n",
    "        \n",
    "        # make sure block has the value in block_index dictionary \n",
    "        # as current seq_number\n",
    "        if len(block_index[block]) != 0 and block_index[block][0] == i:\n",
    "            \n",
    "            # if yes, remove the first element of block_index[block]\n",
    "            block_index[block].popleft()\n",
    "        \n",
    "        # if block exist in current cache\n",
    "        if block in Cache:\n",
    "            \n",
    "            # increment hit\n",
    "            hit += 1\n",
    "            \n",
    "            # update the recency\n",
    "            recency.remove(block)\n",
    "            recency.append(block)\n",
    "            \n",
    "            # update upcoming_index\n",
    "            if i in upcoming_index:\n",
    "                \n",
    "                # delete old index\n",
    "                del upcoming_index[i]\n",
    "        \n",
    "                if len(block_index[block]) is not 0:\n",
    "                    # add new upcoming index\n",
    "                    upcoming_index[block_index[block][0]] = block\n",
    "                    # remove index from block_index\n",
    "                    block_index[block].popleft()\n",
    "                else:\n",
    "                    # add a large integer as index\n",
    "                    upcoming_index[infinite_index] = block\n",
    "                    # increament large integer\n",
    "                    infinite_index-=1\n",
    "           \n",
    "        # block not in current cache\n",
    "        else:\n",
    "            \n",
    "            # increament miss\n",
    "            miss += 1\n",
    "            \n",
    "            # if cache has no free space\n",
    "            if len(Cache) == frame:\n",
    "                  \n",
    "                # find the farthest i.e. max_index in upcoming_index\n",
    "                max_index = max(upcoming_index)\n",
    "                \n",
    "                if (i % 1000 +1 == 1000):\n",
    "                    blockNo = np.array([i for i in Cache])\n",
    "                    blockNo = blockNo / np.linalg.norm(blockNo)\n",
    "                    recency_ = np.array([recency.index(i) for i in Cache])\n",
    "                    recency_ = recency_ / np.linalg.norm(recency_)\n",
    "                    frequency_ = np.array([frequency[i] for i in Cache])\n",
    "                    frequency_ = frequency_ / np.linalg.norm(frequency_)\n",
    "                    stack = np.column_stack((blockNo, recency_, frequency_)).reshape(1,frame*3)\n",
    "                    labelData = np.zeros(int(frame))\n",
    "                    temp_upcomingIndex = Counter({j:i for i,j in upcoming_index.items()})\n",
    "                    mostCommonElements = [i[0] for i in temp_upcomingIndex.most_common(int(frame*perc))]\n",
    "                    mostCommonElementsIndex = [Cache.index(j) for j in mostCommonElements]\n",
    "                    labelData[[mostCommonElementsIndex]] = 1\n",
    "                    stack = np.append(stack, labelData)\n",
    "                    dataset = np.vstack((dataset, stack))\n",
    "                # remove the block with max_index from cache\n",
    "                Cache[Cache.index(upcoming_index[max_index])] = block\n",
    "\n",
    "                # remove the block with max_index from recency dict\n",
    "                recency.remove(upcoming_index[max_index])\n",
    "\n",
    "                # remove max_index element from upcoming_index\n",
    "                del upcoming_index[max_index]\n",
    "                    \n",
    "            \n",
    "            else:\n",
    "                 \n",
    "                # add block into Cache\n",
    "                Cache.append(block)\n",
    "\n",
    "            # add block into recency\n",
    "            recency.append(block)\n",
    "                \n",
    "            # add upcoming request of current block in upcoming_index\n",
    "            if len(block_index[block]) != 0:\n",
    "                \n",
    "                # add upcoming index of block\n",
    "                upcoming_index[block_index[block][0]] = block\n",
    "               \n",
    "                # remove the index from block_index \n",
    "                block_index[block].popleft()\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                # add a large integer as index\n",
    "                upcoming_index[infinite_index] = block\n",
    "                \n",
    "                # increament high number\n",
    "                infinite_index -= 1\n",
    " \n",
    "            \n",
    "    # calculate hitrate\n",
    "    hitrate = hit / (hit + miss)\n",
    "\n",
    "    return hitrate, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='buidling index', max=1322890, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='sequence', max=1322890, style=ProgressStyle(description_widthâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "hitrate, dataset = belady_opt_2(blocktrace, 1000, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05686791, 0.        , 0.02583712, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.05566091, 0.        , 0.03143473, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.05221939, 0.05048311, 0.09352195, ..., 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       ...,\n",
       "       [0.05764424, 0.01227819, 0.03161049, ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.03162163, 0.01227819, 0.03640712, ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.03161963, 0.01227819, 0.02487785, ..., 1.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(dataset[:,:1000*3], dataset[:,1000*3:].astype(int), test_size=0.3, \\\n",
    "                                                    random_state=None, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08333333333333333\n"
     ]
    }
   ],
   "source": [
    "NN_ = MLPClassifier(alpha=0.001,max_iter=200,hidden_layer_sizes=(100,))\n",
    "NN_.fit(X_train, Y_train)\n",
    "\n",
    "print(NN_.score(X_test, Y_test))\n",
    "\n",
    "#print(confusion_matrix(Y_test,NN.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.89261252e-01, 2.47479750e-03, 2.65404309e-03, 2.39137631e-03,\n",
       "        5.36183456e-03, 6.03085639e-03, 5.62941147e-03, 6.10392872e-04,\n",
       "        4.25873524e-04, 5.25568859e-04, 1.62251429e-03, 3.10489225e-06,\n",
       "        2.11008625e-06, 2.68305251e-06, 2.87497405e-06, 1.67032355e-05,\n",
       "        1.08016777e-05, 8.34543988e-01, 2.30255664e-03, 5.83022269e-03,\n",
       "        6.30008590e-03, 1.07011826e-02, 4.53601711e-07, 1.11661557e-04,\n",
       "        3.23861601e-05, 2.22375838e-04, 3.77641940e-04, 1.69900684e-06,\n",
       "        9.50953501e-04, 4.61984978e-03, 2.25004177e-02, 5.49036329e-03,\n",
       "        9.85794305e-01, 6.45597137e-01, 8.94743344e-01, 2.11632240e-03,\n",
       "        1.64397152e-03, 5.83642070e-03, 1.77193783e-05, 1.22831707e-05,\n",
       "        1.16757219e-05, 8.97231259e-06, 7.60048219e-04, 1.29327044e-05,\n",
       "        1.54938503e-05, 9.94018062e-01, 5.75445003e-03, 9.03297947e-03,\n",
       "        5.33755343e-05, 2.21738152e-05, 5.79952682e-04, 9.97289288e-01,\n",
       "        9.94576303e-01, 9.96311545e-01, 5.57876705e-04, 3.53570492e-04,\n",
       "        3.11375241e-04, 3.51435164e-04, 1.06801339e-03, 2.52223214e-04,\n",
       "        2.81298056e-04, 4.82735893e-03, 7.61510234e-03, 3.61964089e-03,\n",
       "        2.64183945e-05, 1.31366742e-03, 4.19864437e-03, 6.35432349e-06,\n",
       "        1.39699498e-05, 9.61138129e-01, 9.59810310e-01, 9.59963704e-01,\n",
       "        4.13304182e-03, 9.63346196e-01, 9.60148493e-01, 6.44392808e-03,\n",
       "        2.87039537e-02, 2.11742690e-05, 6.95857080e-06, 9.63026222e-01,\n",
       "        2.33616487e-07, 1.51654245e-02, 9.63643998e-01, 5.86847638e-08,\n",
       "        5.76932184e-01, 9.74899134e-01, 9.73884219e-01, 9.62679525e-01,\n",
       "        9.54408283e-01, 1.76460775e-03, 1.15394023e-03, 9.92115747e-01,\n",
       "        9.98093035e-01, 1.90589344e-05, 9.86269793e-01, 9.94905023e-01,\n",
       "        1.00074033e-03, 2.67604860e-05, 3.29133568e-05, 9.68761416e-01,\n",
       "        9.69691335e-01, 9.64710810e-01, 9.56948786e-01, 9.87377073e-01,\n",
       "        1.13632664e-05, 1.97868591e-03, 2.21185466e-03, 1.30041302e-02,\n",
       "        3.48684003e-04, 9.91366754e-01, 3.69387922e-04, 9.91727833e-01,\n",
       "        9.95032327e-01, 9.91849716e-01, 8.56621022e-01, 3.30716763e-04,\n",
       "        8.36612767e-06, 7.54881184e-04, 1.24034340e-01, 9.91778586e-01,\n",
       "        9.92818415e-01, 7.40703826e-02, 9.93225058e-01, 2.36156020e-02,\n",
       "        9.93336018e-01, 9.93449139e-01, 9.69633250e-01, 4.92372449e-04,\n",
       "        3.74579881e-04, 3.22368050e-03, 3.36163635e-02, 4.13948906e-02,\n",
       "        2.54342078e-01, 2.63893765e-07, 1.30564580e-04, 8.99057210e-05,\n",
       "        1.20761744e-04, 3.50476123e-05, 1.95193034e-05, 7.61070538e-05,\n",
       "        3.65504121e-04, 9.96972812e-01, 4.32776531e-03, 1.26242608e-03,\n",
       "        7.82407629e-07, 1.22887561e-07, 4.06771368e-04, 3.41702548e-04,\n",
       "        2.72069017e-03, 2.62970345e-04, 9.84760728e-01, 5.97598038e-03,\n",
       "        1.16978082e-05, 1.40119023e-05, 8.96049020e-05, 1.10201085e-04,\n",
       "        9.22138450e-05, 1.06062171e-07, 3.47217006e-08, 4.21532715e-07,\n",
       "        4.55863162e-07, 2.65130980e-04, 6.94956112e-03, 2.32237666e-04,\n",
       "        1.70825284e-05, 3.98063583e-05, 2.82985730e-04, 6.29132759e-04,\n",
       "        3.27208151e-03, 6.53429156e-06, 8.04049639e-04, 5.34478919e-04,\n",
       "        3.12912346e-03, 7.20818794e-04, 8.38271215e-04, 2.23732410e-04,\n",
       "        2.58093051e-03, 5.20750289e-07, 1.39146981e-06, 2.68606089e-05,\n",
       "        1.92062384e-05, 1.98391280e-05, 4.14769147e-04, 6.42571198e-04,\n",
       "        1.54946986e-04, 1.18500667e-04, 1.56723037e-04, 9.01635733e-05,\n",
       "        8.86785771e-05, 1.31098615e-04, 4.75191098e-04, 3.70946773e-04,\n",
       "        3.87655485e-04, 4.32029324e-04, 3.48343915e-04, 2.23206320e-03,\n",
       "        7.94658979e-04, 2.78385168e-03, 1.36927958e-04, 7.86597667e-04,\n",
       "        1.68591672e-04, 1.07755436e-04, 9.79976401e-01, 9.72717879e-01,\n",
       "        3.40647091e-04, 4.20735670e-04, 9.95943332e-01, 9.62601016e-01,\n",
       "        8.59618141e-07, 5.46320021e-04, 1.74073451e-05, 1.67772896e-07,\n",
       "        1.95472134e-06, 8.09568328e-07, 3.60194643e-04, 2.51335697e-05,\n",
       "        1.89889642e-05, 1.40000394e-05, 1.85057019e-05, 2.04378230e-04,\n",
       "        1.43922555e-04, 1.29569889e-04, 2.15796300e-04, 3.23752842e-06,\n",
       "        6.09386510e-05, 6.26759994e-07, 6.91203399e-06, 3.44651379e-05,\n",
       "        3.97689366e-06, 1.48861795e-04, 1.12879211e-04, 3.92807018e-05,\n",
       "        1.26080859e-04, 1.39276860e-04, 8.99029926e-05, 1.35123985e-04,\n",
       "        1.15139058e-05, 2.46077061e-06, 1.89013335e-06, 2.29995654e-06,\n",
       "        2.07589931e-06, 4.28832005e-03, 3.63636333e-03, 5.24836986e-03,\n",
       "        8.17118618e-06, 6.90803694e-05, 6.35705747e-05, 1.80148061e-06,\n",
       "        5.25122968e-05, 1.33121518e-04, 1.12547025e-04, 1.49327931e-05,\n",
       "        1.37914547e-06, 2.93750437e-05, 7.92720662e-03, 4.27695957e-05,\n",
       "        4.52312314e-06, 1.40716436e-04, 4.57340592e-04, 5.28543710e-04,\n",
       "        2.14449563e-04, 2.55195064e-04, 5.99855977e-06, 8.15446582e-06,\n",
       "        4.77398599e-04, 3.91491339e-06, 1.30961754e-05, 1.15484180e-02,\n",
       "        1.73225879e-02, 6.36662396e-05, 1.23350400e-04, 9.89884944e-01,\n",
       "        9.99269957e-05, 1.86133465e-04, 3.11810229e-04, 6.12648937e-06,\n",
       "        2.82761031e-06, 1.55908798e-06, 2.17290981e-06, 2.61750519e-06,\n",
       "        3.35149680e-06, 8.68735873e-07, 2.29678305e-06, 1.99002173e-06,\n",
       "        5.77765409e-06, 7.04241659e-06, 2.19125451e-04, 1.81049322e-04,\n",
       "        2.46133745e-04, 2.96510446e-04, 1.30506899e-04, 3.03227152e-04,\n",
       "        7.30667753e-05, 1.47760559e-04, 3.85891799e-04, 5.38276078e-06,\n",
       "        5.90874532e-06, 2.66950687e-04, 1.81432187e-02, 5.79065470e-04,\n",
       "        5.55416918e-04, 6.53484898e-04, 2.10943447e-04, 1.86164901e-04,\n",
       "        1.30150177e-04, 2.06179050e-04, 2.25212014e-04, 4.89894806e-07,\n",
       "        5.03527665e-04, 1.80587897e-04, 1.70569045e-04, 1.22254435e-03,\n",
       "        3.19286312e-04, 2.95058821e-04, 4.14944257e-05, 3.48022294e-04,\n",
       "        1.55976875e-04, 1.28084891e-02, 2.72085762e-04, 9.18432424e-05,\n",
       "        6.67359574e-06, 1.70734119e-05, 2.44892441e-04, 4.86882640e-03,\n",
       "        8.98976373e-04, 9.79619586e-01, 9.59868088e-04, 9.98581629e-01,\n",
       "        2.01380559e-06, 1.07061442e-06, 6.79522621e-07, 6.97301208e-06,\n",
       "        1.14706298e-05, 3.43676125e-06, 2.08757584e-05, 9.96729207e-01,\n",
       "        9.95952875e-01, 9.89431419e-01, 9.99675347e-01, 9.97152176e-01,\n",
       "        9.95422676e-01, 2.97491548e-03, 9.95754132e-01, 8.36613723e-06,\n",
       "        4.39404726e-05, 8.27044943e-06, 2.76492728e-05, 9.97862306e-01,\n",
       "        7.46318972e-04, 1.17159471e-05, 1.28482331e-04, 1.34841953e-05,\n",
       "        1.61996763e-06, 4.76783712e-05, 6.48796859e-08, 5.00865616e-05,\n",
       "        3.05425325e-05, 3.63098526e-03, 9.29660163e-05, 1.17865797e-04,\n",
       "        2.98201091e-03, 1.11866760e-02, 9.94609095e-01, 6.81670261e-04,\n",
       "        3.01377682e-06, 8.50356830e-05, 6.06606168e-06, 1.04049434e-04,\n",
       "        1.46367178e-04, 2.11551419e-05, 3.11215968e-07, 7.21798911e-05,\n",
       "        1.94580833e-03, 9.17493639e-05, 1.01324922e-04, 2.29575331e-04,\n",
       "        7.30428079e-06, 1.55208772e-04, 2.13632444e-04, 3.08308109e-05,\n",
       "        3.44330237e-05, 1.37477742e-04, 3.86332123e-03, 1.38066480e-04,\n",
       "        3.37695172e-04, 1.04326197e-04, 6.44474869e-04, 1.19847326e-03,\n",
       "        1.25363922e-04, 1.62387742e-03, 2.26395573e-05, 3.50238415e-05,\n",
       "        1.01837052e-05, 2.23867757e-05, 1.24511749e-04, 9.73539242e-05,\n",
       "        3.29704401e-05, 1.20291901e-04, 4.38775691e-04, 4.72372260e-04,\n",
       "        4.20428486e-04, 1.69411482e-06, 5.50559814e-06, 3.48219416e-07,\n",
       "        5.68108048e-05, 2.19742557e-06, 9.53170360e-07, 1.89112038e-06,\n",
       "        8.96721948e-06, 9.94673579e-01, 9.93278983e-01, 9.88427275e-01,\n",
       "        9.92081139e-01, 9.85031599e-01, 9.83422148e-01, 6.30783403e-03,\n",
       "        5.21784208e-04, 4.43319280e-04, 1.49110401e-04, 8.72297762e-06,\n",
       "        7.77924521e-06, 1.36156216e-05, 4.43234319e-04, 6.99662573e-04,\n",
       "        4.81435717e-03, 3.07415711e-07, 5.06832750e-04, 9.76619386e-01,\n",
       "        9.84862967e-01, 1.71835936e-05, 2.38394013e-04, 1.08682301e-05,\n",
       "        8.57133469e-06, 9.49122535e-06, 9.99365366e-05, 1.14147264e-04,\n",
       "        6.12638045e-02, 4.31713278e-05, 2.93912622e-05, 4.52136330e-05,\n",
       "        2.78585349e-04, 5.33897605e-04, 9.93809800e-01, 3.27024913e-05,\n",
       "        3.61625495e-05, 3.17181413e-04, 3.32138086e-04, 8.57683038e-05,\n",
       "        2.51205076e-04, 2.04400943e-05, 1.13820064e-05, 7.61585516e-06,\n",
       "        3.52096530e-04, 4.48050766e-04, 4.69830888e-05, 6.33385090e-05,\n",
       "        1.27817804e-05, 2.90787942e-03, 9.04582561e-05, 3.51276491e-04,\n",
       "        4.68311290e-04, 5.93884587e-03, 1.00638131e-04, 1.55222157e-04,\n",
       "        1.06435755e-04, 2.37592166e-03, 4.92190188e-03, 1.35301824e-04,\n",
       "        7.37490373e-03, 1.65818354e-04, 1.05165095e-05, 8.27569644e-05,\n",
       "        1.12343353e-04, 3.98467685e-04, 4.19866708e-05, 4.30093418e-05,\n",
       "        1.14939469e-04, 1.82348914e-05, 8.11521582e-04, 3.30683225e-03,\n",
       "        7.38771136e-04, 7.00375659e-04, 8.52186740e-04, 3.88379461e-04,\n",
       "        1.20117407e-02, 5.01683048e-05, 9.43882938e-04, 7.91096782e-04,\n",
       "        7.76982670e-04, 8.75961344e-01, 4.39748315e-05, 8.91740161e-04,\n",
       "        2.87904620e-05, 6.76185993e-05, 3.71435049e-05, 1.50569292e-04,\n",
       "        7.76672546e-06, 1.89187757e-05, 7.06654459e-04, 5.41855218e-04,\n",
       "        9.94809278e-03, 1.26746153e-06, 5.94672433e-04, 9.97153462e-01,\n",
       "        2.31603572e-04, 9.39577281e-06, 3.68655549e-06, 4.22562880e-04,\n",
       "        4.39944472e-04, 4.48552922e-04, 1.63958000e-03, 5.26794744e-04,\n",
       "        6.26777008e-04, 1.09763689e-02, 4.49217338e-05, 9.97371995e-01,\n",
       "        1.50784121e-02, 6.02707120e-04, 1.06139255e-03, 7.92661619e-04,\n",
       "        1.01956576e-04, 1.27574772e-04, 1.15022100e-07, 3.49496433e-05,\n",
       "        9.20993929e-05, 9.14096825e-05, 7.48446146e-06, 1.88354753e-04,\n",
       "        2.14153373e-05, 2.32064882e-04, 5.53658252e-04, 6.22802913e-04,\n",
       "        8.49938939e-04, 7.52884057e-04, 3.77238668e-08, 1.44283071e-05,\n",
       "        1.71196619e-04, 2.00624458e-04, 4.56432788e-05, 1.30430941e-03,\n",
       "        1.71344864e-05, 2.54311981e-05, 5.23348407e-05, 5.49242641e-05,\n",
       "        5.66642224e-08, 5.76561416e-05, 6.57781391e-01, 1.05687287e-03,\n",
       "        1.96091140e-04, 1.15218901e-05, 1.49832046e-04, 2.13281190e-04,\n",
       "        1.02401244e-05, 1.00137796e-05, 7.60827124e-04, 3.25262150e-05,\n",
       "        6.18685682e-05, 7.23415164e-04, 1.73272222e-04, 9.97637892e-01,\n",
       "        2.17297205e-05, 2.01140055e-05, 8.62416816e-04, 2.10116448e-03,\n",
       "        1.48049899e-03, 6.20649479e-04, 1.50234243e-05, 4.47952878e-06,\n",
       "        9.09850865e-06, 1.06007656e-04, 2.80163196e-05, 2.05530018e-05,\n",
       "        3.44884371e-05, 7.16649058e-04, 1.59804946e-03, 8.42009552e-04,\n",
       "        1.39773781e-04, 4.30815637e-06, 6.61714422e-03, 3.99472093e-03,\n",
       "        5.12888408e-05, 5.74717694e-05, 5.21733995e-05, 5.35975794e-05,\n",
       "        7.38157776e-04, 5.35550227e-05, 5.64877987e-05, 2.17923566e-04,\n",
       "        4.34769009e-05, 4.69633872e-08, 1.71999633e-07, 7.89826169e-01,\n",
       "        2.70791974e-05, 5.74990506e-05, 4.35915689e-05, 1.97604805e-05,\n",
       "        6.85750521e-04, 8.58519920e-04, 2.46828043e-06, 1.50018827e-03,\n",
       "        2.10441351e-06, 1.24300574e-05, 5.00665308e-08, 6.15582108e-05,\n",
       "        4.01257636e-05, 1.05043389e-05, 1.80905606e-05, 2.88076026e-05,\n",
       "        2.30414042e-05, 4.47790676e-05, 3.57961424e-05, 5.84614594e-05,\n",
       "        3.48000818e-05, 4.15049027e-05, 4.77918478e-05, 2.08469570e-05,\n",
       "        3.03950656e-05, 1.27708137e-04, 7.43853867e-05, 1.81410249e-04,\n",
       "        1.08667045e-04, 1.07452613e-04, 2.44551353e-05, 1.04580739e-04,\n",
       "        2.98129350e-05, 3.61657730e-05, 7.21781008e-06, 1.46557967e-05,\n",
       "        1.64897970e-05, 1.04104907e-05, 9.64413931e-06, 6.00975903e-06,\n",
       "        5.86891677e-06, 6.33321489e-05, 7.40741871e-06, 3.04128289e-05,\n",
       "        4.91711816e-05, 3.87282988e-05, 2.29881511e-05, 1.80835226e-05,\n",
       "        4.74455184e-05, 7.91777370e-01, 5.90514912e-05, 7.81260567e-05,\n",
       "        8.37825242e-05, 1.04619406e-04, 3.33547423e-06, 1.06315058e-04,\n",
       "        4.14782035e-05, 9.33033822e-05, 1.47621556e-05, 5.22395988e-04,\n",
       "        1.13533227e-05, 2.81312466e-05, 1.29468454e-05, 1.28462426e-05,\n",
       "        1.86402492e-04, 1.25500283e-04, 1.56878983e-04, 2.41689524e-05,\n",
       "        3.76890679e-03, 6.92846689e-04, 2.02058300e-04, 1.44699904e-04,\n",
       "        2.39198771e-06, 7.51785059e-05, 1.79780667e-04, 7.06179591e-08,\n",
       "        1.05836026e-07, 9.30072898e-08, 3.05394666e-07, 1.89223151e-04,\n",
       "        9.83161327e-04, 1.56786833e-01, 3.93498649e-05, 1.90876679e-04,\n",
       "        6.11484651e-05, 2.11038412e-04, 2.27037398e-04, 9.68088826e-04,\n",
       "        1.02855911e-03, 5.46369425e-05, 1.23025792e-05, 6.61819833e-05,\n",
       "        1.52836134e-03, 2.35216443e-04, 4.86244636e-05, 7.90687776e-06,\n",
       "        5.74223555e-05, 1.21585942e-03, 1.57225176e-04, 2.10654848e-05,\n",
       "        3.20843657e-05, 5.15267037e-06, 8.78606838e-08, 7.07314361e-05,\n",
       "        1.15427119e-04, 2.63013242e-05, 1.74793025e-05, 4.07340327e-05,\n",
       "        4.33344659e-05, 1.01952750e-04, 2.85425508e-03, 2.08188859e-03,\n",
       "        4.50434541e-05, 3.59493881e-05, 2.04380007e-04, 1.75691450e-04,\n",
       "        2.50486967e-04, 9.68430869e-04, 4.94709783e-01, 7.11875128e-05,\n",
       "        2.86886966e-05, 3.12111412e-05, 1.47980303e-04, 7.52234877e-06,\n",
       "        1.97975864e-05, 3.62129012e-04, 8.21435845e-06, 1.95877659e-02,\n",
       "        2.79444335e-05, 3.01791961e-05, 3.92191006e-04, 9.94472077e-01,\n",
       "        3.67320004e-04, 1.41487901e-04, 1.00297486e-04, 7.06808244e-05,\n",
       "        2.01193874e-02, 2.34599799e-02, 6.82895055e-03, 3.42463936e-08,\n",
       "        2.80028955e-06, 1.10412551e-03, 1.98827845e-05, 2.08823436e-02,\n",
       "        9.96732769e-01, 5.73153274e-03, 1.19568524e-06, 1.95384881e-03,\n",
       "        1.79607567e-03, 1.25430609e-05, 3.06100414e-04, 4.22151719e-04,\n",
       "        3.73383825e-04, 2.30959900e-05, 8.99821163e-02, 1.65685663e-04,\n",
       "        3.59568848e-02, 2.15949035e-04, 2.26120570e-06, 1.53229271e-05,\n",
       "        5.48162921e-06, 7.21999727e-08, 2.82148571e-08, 7.28393664e-04,\n",
       "        7.98785744e-05, 3.39627681e-05, 1.09574646e-04, 9.05895482e-05,\n",
       "        4.22663031e-06, 7.98217120e-05, 9.21840946e-07, 9.82064372e-01,\n",
       "        9.95286851e-01, 9.96583552e-01, 7.92883327e-05, 5.09794310e-05,\n",
       "        2.19995805e-04, 4.73040372e-03, 4.84418167e-03, 5.20520534e-02,\n",
       "        5.06450103e-03, 4.83836871e-03, 2.10210323e-03, 1.65059435e-07,\n",
       "        9.91654598e-01, 6.88023406e-05, 5.80260924e-06, 2.40987337e-04,\n",
       "        9.86927859e-01, 1.22131926e-05, 1.40677687e-05, 1.09716438e-05,\n",
       "        2.20309891e-01, 9.41210576e-01, 1.10250399e-05, 1.92232866e-03,\n",
       "        1.46633660e-04, 1.36128969e-05, 2.47139141e-04, 1.14798174e-03,\n",
       "        2.34793174e-04, 4.07910068e-04, 4.73287642e-04, 6.23651487e-05,\n",
       "        5.92578038e-06, 8.97352204e-06, 8.51458169e-06, 9.54860749e-06,\n",
       "        1.70021827e-05, 2.19866722e-05, 5.22914196e-06, 2.15067249e-05,\n",
       "        2.14707578e-05, 3.38778828e-05, 9.16702453e-05, 3.85580525e-05,\n",
       "        5.78484989e-03, 1.30166763e-04, 1.13738939e-05, 1.16162630e-05,\n",
       "        1.40659663e-03, 9.37450961e-04, 2.27908424e-04, 3.20988611e-01,\n",
       "        1.78181462e-04, 5.21358864e-06, 1.37070339e-04, 1.44524209e-04,\n",
       "        9.97954105e-01, 3.30772393e-04, 1.17765467e-03, 1.04300831e-02,\n",
       "        8.11455658e-04, 1.34980164e-04, 4.04465617e-05, 4.10269670e-05,\n",
       "        1.91033926e-04, 2.78633658e-02, 4.16764906e-05, 8.35754408e-07,\n",
       "        3.80362693e-04, 5.06655356e-06, 2.75654376e-02, 8.85405665e-03,\n",
       "        2.85224990e-05, 7.53029685e-04, 3.21785208e-06, 1.18435215e-05,\n",
       "        1.34537554e-04, 1.08978987e-04, 8.66480986e-02, 1.65156623e-01,\n",
       "        2.34859229e-01, 3.61603017e-02, 5.50565031e-06, 1.12402915e-02,\n",
       "        2.46313617e-02, 1.09344633e-02, 3.06964058e-03, 9.80929668e-03,\n",
       "        6.84859473e-06, 5.66780261e-04, 6.91903058e-05, 9.82162348e-03,\n",
       "        2.97218227e-03, 4.00276192e-05, 9.92146906e-04, 7.93690038e-03,\n",
       "        9.88328762e-01, 6.17056585e-01, 7.45684107e-01, 1.00263091e-02,\n",
       "        3.94102344e-03, 3.83385897e-03, 5.31710843e-03, 5.06971710e-03,\n",
       "        4.26788520e-04, 2.37318513e-06, 4.29141278e-02, 3.49099717e-03,\n",
       "        4.26863962e-03, 1.39373610e-06, 2.49580454e-06, 9.86879225e-01,\n",
       "        1.42000931e-06, 3.89590081e-05, 9.87590978e-01, 9.88804033e-01,\n",
       "        9.63881122e-01, 3.71623958e-05, 1.14078450e-04, 1.15055249e-05,\n",
       "        5.10803985e-03, 6.53944177e-05, 3.76390306e-05, 6.40136701e-04,\n",
       "        3.54693643e-04, 1.34384637e-05, 8.85732163e-06, 8.60602140e-06,\n",
       "        1.41869559e-05, 8.33692263e-03, 8.63206660e-03, 8.32331759e-01,\n",
       "        2.66958597e-04, 2.14386930e-04, 3.05235381e-03, 8.24552712e-05,\n",
       "        4.12726079e-05, 7.33834102e-05, 7.46057317e-05, 1.00212359e-04,\n",
       "        2.82460280e-05, 3.72913929e-05, 3.89904461e-05, 6.24259944e-05,\n",
       "        8.92128342e-01, 7.35707744e-04, 4.99611523e-05, 4.24186202e-05,\n",
       "        9.78941612e-06, 5.82853432e-03, 5.93698358e-02, 1.77568498e-01,\n",
       "        6.50481114e-06, 6.84560618e-06, 3.80315424e-03, 3.51293873e-06,\n",
       "        2.43117821e-06, 6.25150047e-03, 3.08629025e-06, 1.30570057e-05,\n",
       "        1.32032914e-05, 2.13475427e-04, 2.65007559e-04, 2.70723575e-05,\n",
       "        8.99320184e-01, 9.88016913e-01, 9.93839359e-01, 4.85748808e-03,\n",
       "        9.78123643e-03, 2.13613651e-04, 1.31115445e-03, 7.60167123e-04,\n",
       "        1.63466423e-04, 1.54851469e-03, 1.38300116e-04, 5.77609201e-05,\n",
       "        4.16884730e-04, 4.18398980e-05, 5.00271116e-05, 3.14592493e-05,\n",
       "        2.37816573e-05, 2.20099882e-05, 4.97242114e-06, 4.61886602e-06,\n",
       "        1.24929940e-04, 2.84135414e-05, 2.06125789e-05, 4.80299523e-05,\n",
       "        3.92649077e-05, 5.50942673e-05, 4.48880417e-04, 3.90969905e-04,\n",
       "        2.32470789e-04, 1.12228857e-03, 9.21846796e-03, 2.82855859e-02,\n",
       "        3.80784538e-02, 1.20362990e-02, 4.81485804e-03, 4.50144937e-03,\n",
       "        4.90177562e-03, 2.76135610e-05, 2.83067931e-05, 2.68553563e-05,\n",
       "        2.23565634e-05, 1.36766649e-05, 4.74665090e-03, 7.35423452e-04,\n",
       "        1.58724139e-05, 1.19053265e-05, 1.04712453e-06, 2.57050881e-06,\n",
       "        5.07837923e-06, 3.19774961e-06, 9.81653249e-01, 1.03221493e-03,\n",
       "        6.58930840e-03, 6.84803714e-03, 7.19925515e-04, 7.56996607e-03,\n",
       "        7.49807289e-03, 1.28335102e-03, 2.37095845e-04, 1.95930597e-03,\n",
       "        2.80678115e-04, 1.45052802e-05, 3.99350975e-04, 8.79837845e-06,\n",
       "        9.88312927e-01, 2.37342471e-04, 1.45663860e-01, 1.45323857e-02,\n",
       "        9.89718897e-01, 9.26127335e-01, 2.16712376e-01, 1.05070457e-03]])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_.predict_proba([X_test[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "        1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "        0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 1, 1, 0, 0]])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_.predict([X_test[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Hitrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ML_policy_2(blocktrace,frame, model):\n",
    "    '''\n",
    "    INPUT\n",
    "    ==========\n",
    "    blocktrace = list of block request sequence\n",
    "    frame = size of the cache\n",
    "    model = trained ML model\n",
    "    \n",
    "    OUTPUT\n",
    "    ==========\n",
    "    hitrate \n",
    "    '''\n",
    "    #global sample_interval # interval of choice for sampling\n",
    "    infinite_index = 100 * len(blocktrace) # should be a large integer\n",
    "    \n",
    "    \n",
    "    frequency = defaultdict(int)\n",
    "    # dictionary of block as key and number\n",
    "    # of times it's been requested so far\n",
    "    \n",
    "    recency = list()\n",
    "    # list of block in order of their request\n",
    "    \n",
    "    Cache = deque()\n",
    "    # Cache with block\n",
    "    \n",
    "    bufferCache = Counter()\n",
    "    # initialize bufferCache\n",
    "    \n",
    "    hit, miss = 0, 0\n",
    "    \n",
    "    # sequential block requests start\n",
    "    for i, block in enumerate(tqdm(blocktrace, desc=\"sequence\", leave=False)):\n",
    "        \n",
    "        # increament the frequency number for the block\n",
    "        frequency[block] += 1\n",
    "        \n",
    "        # if block exist in current cache\n",
    "        if block in Cache:\n",
    "            \n",
    "            # increment hit\n",
    "            hit += 1\n",
    "            \n",
    "            if Cache.index(block) in bufferCache:\n",
    "                bufferCache.remove(Cache.index(block))\n",
    "            \n",
    "            # update the recency\n",
    "            recency.remove(block)\n",
    "            recency.append(block)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            # increament miss\n",
    "            miss += 1\n",
    "            \n",
    "            # if cache has no free space\n",
    "            if len(Cache) == frame:\n",
    "                \n",
    "                if len(bufferCache) == 0:\n",
    "\n",
    "                    blockNo = np.array([i for i in Cache])\n",
    "                    blockNo = blockNo / np.linalg.norm(blockNo)\n",
    "                    recency_ = np.array([recency.index(i) for i in Cache])\n",
    "                    recency_ = recency_ / np.linalg.norm(recency_)\n",
    "                    frequency_ = np.array([frequency[i] for i in Cache])\n",
    "                    frequency_ = frequency_ / np.linalg.norm(frequency_)\n",
    "                    stack = np.column_stack((blockNo, recency_, frequency_)).reshape(1,frame*3)\n",
    "\n",
    "                    X_current = model.predict_proba(stack)\n",
    "                    max_block=X_current.argsort()[-100:]\n",
    "                    for i in max_block[0]:\n",
    "                        bufferCache[Cache[i]] = i\n",
    "                \n",
    "                mostcommon = bufferCache.most_common(1)[0][0]\n",
    "                Cache.remove(mostcommon)\n",
    "                del bufferCache[mostcommon]\n",
    "\n",
    "\n",
    "            else:\n",
    "                # add block into Cache\n",
    "                Cache.append(block)\n",
    "\n",
    "            # add block into recency\n",
    "            recency.append(block)\n",
    "\n",
    "\n",
    "    # calculate hitrate\n",
    "    hitrate = hit / (hit + miss)\n",
    "\n",
    "    return hitrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='sequence', max=1322890, style=ProgressStyle(description_widthâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s = ML_policy_2(blocktrace, 1000, NN_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010261624171321879"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [1,2,3,4,5,67]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Counter(a=4, b=2, c=0, d=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'a': 4, 'b': 2, 'c': 0, 'd': -2})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.most_common(1)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-139e54ee8b11>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "c.most_common(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OPT: building index: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 652710/652710 [00:00<00:00, 1090176.44it/s]\n",
      "OPT: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 652710/652710 [00:29<00:00, 22316.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22377472384366717\n",
      "size of X 518000\n",
      "Test Y\n",
      "size of X 510000\n",
      "size of Y 510000\n",
      "Test Y_test\n",
      "size of X_train 357000\n",
      "size of X_test 153000\n",
      "======================================\n",
      "[[0.94833497 0.05166503]]\n",
      "0\n",
      "=======================================\n",
      "[[  1.21755115  -4.20131699 121.72285148]]\n",
      "LFU Correct / Incorrect Ratio\n",
      "0.8208185328185328\n",
      "LRU Correct / Incorrect Ratio\n",
      "0.8216756756756757\n",
      "logRegCorrect = 151454\n",
      "logRegInorrect = 1546\n",
      "correct = 0.9898954248366013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OPT: building index: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 195813/195813 [00:00<00:00, 1356152.06it/s]\n",
      "OPT: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 195813/195813 [00:08<00:00, 22437.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3134112648291993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OPT: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 195813/195813 [00:04<00:00, 40499.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.024257837835077345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 195813/195813 [00:12<00:00, 15658.94it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.25379315980042183"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[458]:\n",
    "\n",
    "from tqdm import tqdm as tqdm \n",
    "import numpy as np\n",
    "from collections import deque, defaultdict\n",
    "import timeit\n",
    "import pandas as pd\n",
    "import random\n",
    "from collections import Counter\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import sys\n",
    "\n",
    "# dummy maxmimum position variable. assign the position of blocks that \n",
    "# will never get accessed a value greater than this value. this way OPT\n",
    "# can be fooled to think that the block will be accessed but at a position\n",
    "# far-far-away in time.\n",
    "\n",
    "maxpos = 1000000000000\n",
    "\n",
    "num_params = 3\n",
    "sampling_freq = 1000 # number of samples skipped\n",
    "cache_size = 1000    # default cache size\n",
    "eviction = int(0.1 * cache_size)  # number of blocks evicted\n",
    "filename = \"ikki-110108-112108.1.blkparse\"\n",
    "#filename = \"cheetah.1000\"\n",
    "\n",
    "df = pd.read_csv(filename, sep=' ',header = None)\n",
    "df.columns = ['timestamp','pid','pname','blockNo', 'blockSize', 'readOrWrite', 'bdMajor', 'bdMinor', 'hash']\n",
    "df.head()\n",
    "\n",
    "# In[460]:\n",
    "\n",
    "blocktrace = df['blockNo'].tolist()\n",
    "\n",
    "timestamp = df['timestamp'].tolist()\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "le.fit(df['pid'].tolist())\n",
    "\n",
    "pid = le.transform(df['pid'].tolist())\n",
    "\n",
    "\n",
    "# In[466]:\n",
    "\n",
    "\n",
    "#LRU(blocktrace, 500)\n",
    "\n",
    "\n",
    "# In[467]:\n",
    "\n",
    "\n",
    "def LFU(blocktrace, frame):\n",
    "    \n",
    "    cache = set()\n",
    "    cache_frequency = defaultdict(int)\n",
    "    frequency = defaultdict(int)\n",
    "    \n",
    "    hit, miss = 0, 0\n",
    "    \n",
    "    for block in tqdm(blocktrace):\n",
    "        frequency[block] += 1\n",
    "        \n",
    "        if block in cache:\n",
    "            hit += 1\n",
    "            cache_frequency[block] += 1\n",
    "        \n",
    "        elif len(cache) < frame:\n",
    "            cache.add(block)\n",
    "            cache_frequency[block] += 1\n",
    "            miss += 1\n",
    "\n",
    "        else:\n",
    "            e, f = min(cache_frequency.items(), key=lambda a: a[1])\n",
    "            cache_frequency.pop(e)\n",
    "            cache.remove(e)\n",
    "            cache.add(block)\n",
    "            cache_frequency[block] = frequency[block]\n",
    "            miss += 1\n",
    "    \n",
    "    hitrate = hit / ( hit + miss )\n",
    "    return hitrate\n",
    "\n",
    "'''\n",
    "    given C, use LFUDict to find eviction number of blocks from the Cache\n",
    "    compare it with Y_OPT and store number of places the two differ\n",
    "'''\n",
    "lruCorrect = 0\n",
    "lruIncorrect = 0\n",
    "\n",
    "def lruPredict(C,LRUQ,Y_OPT):\n",
    "    global lruCorrect, lruIncorrect\n",
    "    Y_current = []\n",
    "    KV = defaultdict(int)\n",
    "    for i in range(len(LRUQ)):\n",
    "        KV[LRUQ[i]] = len(LRUQ) - i\n",
    "    KV_sorted = Counter(KV)\n",
    "    evict_dict = dict(KV_sorted.most_common(eviction))\n",
    "    for e in C:\n",
    "        if e in evict_dict:\n",
    "            Y_current.append(1)\n",
    "        else:\n",
    "            Y_current.append(0)\n",
    "    for i in range(len(Y_current)):\n",
    "        if Y_current[i] is Y_OPT[i]:\n",
    "            lruCorrect+=1\n",
    "        else:\n",
    "            lruIncorrect+=1\n",
    "    return Y_current\n",
    "\n",
    "# returns sequence of blocks in prioirty order\n",
    "\n",
    "def Y_getBlockSeq(Y_pred_prob):\n",
    "    x = []\n",
    "    for i in range(len(Y_pred_prob)):\n",
    "        x.append(Y_pred_prob[i][0])\n",
    "    x = np.array(x)\n",
    "    idx = np.argsort(x)\n",
    "    idx = idx[:eviction]\n",
    "    return idx\n",
    "\n",
    "def Y_getMinPredict(Y_pred_prob):\n",
    "    x = []\n",
    "    for i in range(len(Y_pred_prob)):\n",
    "        x.append(Y_pred_prob[i][0])\n",
    "    x = np.array(x)\n",
    "    idx = np.argpartition(x, eviction)\n",
    "    \n",
    "    Y_pred = np.zeros(len(Y_pred_prob), dtype=int)\n",
    "    for i in range(eviction):\n",
    "        Y_pred[idx[i]] = 1\n",
    "    assert(Counter(Y_pred)[1] == eviction)\n",
    "    return Y_pred\n",
    "\n",
    "'''\n",
    "    given C, use LFUDict to find eviction number of blocks from the Cache\n",
    "    compare it with Y_OPT and store number of places the two differ\n",
    "\n",
    "    The number of correct and incorrect predictions with respect to OPT.\n",
    "'''\n",
    "\n",
    "lfuCorrect = 0\n",
    "lfuIncorrect = 0\n",
    "\n",
    "def lfuPredict(C,LFUDict,Y_OPT):\n",
    "    global lfuCorrect, lfuIncorrect\n",
    "    Y_current = []\n",
    "    KV = defaultdict()\n",
    "    for e in C:\n",
    "        KV[e] = LFUDict[e]\n",
    "    KV_sorted = Counter(KV)\n",
    "    evict_dict = dict(KV_sorted.most_common(eviction))\n",
    "    for e in C:\n",
    "        if e in evict_dict:\n",
    "            Y_current.append(1)\n",
    "        else:\n",
    "            Y_current.append(0)\n",
    "    for i in range(len(Y_current)):\n",
    "        if Y_current[i] is Y_OPT[i]:\n",
    "            lfuCorrect+=1\n",
    "        else:\n",
    "            lfuIncorrect+=1\n",
    "    return Y_current\n",
    "\n",
    "# return \"eviction\" blocks that are being accessed furthest\n",
    "# from the cache that was sent to us.\n",
    "\n",
    "def getY(C,D):\n",
    "    assert(len(C) == len(D))\n",
    "    Y_current = []\n",
    "    KV_sorted = Counter(D)\n",
    "    evict_dict = dict(KV_sorted.most_common(eviction))\n",
    "    assert(len(evict_dict) == eviction)\n",
    "    all_vals = evict_dict.values()\n",
    "    for e in C:\n",
    "        if e in evict_dict.values():\n",
    "            Y_current.append(1)\n",
    "        else:\n",
    "            Y_current.append(0)\n",
    "    #print (Y_current.count(1))\n",
    "    assert(Y_current.count(1) == eviction)\n",
    "    assert((set(all_vals)).issubset(set(C)))\n",
    "    return Y_current\n",
    "\n",
    "def getLFURow(LFUDict, C):\n",
    "    x_lfurow = []\n",
    "    for e in C:\n",
    "        x_lfurow.append(LFUDict[e])\n",
    "    norm = x_lfurow / np.linalg.norm(x_lfurow)\n",
    "    return norm\n",
    "    \n",
    "def getLRURow(LRUQ, C):\n",
    "    x_lrurow = []\n",
    "    KV = defaultdict(int)\n",
    "    for i in range(len(LRUQ)):\n",
    "        KV[LRUQ[i]] = len(C) - i\n",
    "    for e in C:\n",
    "        x_lrurow.append(KV[e])\n",
    "    norm = x_lrurow / np.linalg.norm(x_lrurow)\n",
    "    return norm\n",
    "\n",
    "def normalize(feature, blocks):\n",
    "    x_feature = []\n",
    "    for i in range(len(blocks)):\n",
    "        x_feature.append(feature[blocks[i]])\n",
    "    return x_feature / np.linalg.norm(x_feature)\n",
    "\n",
    "def getX(LRUQ, LFUDict, C, CacheTS, CachePID):\n",
    "    X_lfurow = getLFURow(LFUDict, C)\n",
    "    X_lrurow = getLRURow(LRUQ, C)\n",
    "    X_bno    = C / np.linalg.norm(C)\n",
    "#     X_ts     = normalize(CacheTS, C)\n",
    "#     X_pid    = normalize(CachePID, C)\n",
    "    return (np.column_stack((X_lfurow, X_lrurow, X_bno)))\n",
    "    \n",
    "# appends OPT sample to X, Y arrays\n",
    "\n",
    "X = np.array([], dtype=np.int64).reshape(0,num_params)\n",
    "Y = np.array([], dtype=np.int64).reshape(0,1)\n",
    "\n",
    "# C - cache, LFUDict - dictionary containing block-> access frequency\n",
    "# LRUQ - order of element access in Cache.\n",
    "\n",
    "def populateData(LFUDict, LRUQ, C, D, CacheTS, CachePID):\n",
    "    global X,Y\n",
    "    C = list(C)\n",
    "    Y_current = getY(C, D)\n",
    "    X_current = getX(LRUQ, LFUDict, C, CacheTS, CachePID)\n",
    "\n",
    "    Y = np.append(Y, Y_current)\n",
    "    X = np.concatenate((X,X_current))\n",
    "    assert(Y_current.count(1) == eviction)\n",
    "    return Y_current\n",
    "\n",
    "#D - dictionary for faster max() finding among available blocks\n",
    "#this dictionary contains next_position -> block_number of blocks in Cache\n",
    "#LFUDict - dictionary containing {block -> access_frequencies}\n",
    "#LRUQ - deque of all elements in cache based on recency of access\n",
    "\n",
    "def belady_opt(blocktrace, frame):\n",
    "    global maxpos\n",
    "    OPT = defaultdict(deque)\n",
    "    D = defaultdict(int)\n",
    "    LFUDict = defaultdict(int)\n",
    "    LRUQ = []\n",
    "    CacheTS = defaultdict(int)\n",
    "    CachePID = defaultdict(int)\n",
    "\n",
    "    for i, block in enumerate(tqdm(blocktrace, desc=\"OPT: building index\")):\n",
    "        OPT[block].append(i)\n",
    "\n",
    "    hit, miss = 0, 0\n",
    "\n",
    "    C = []\n",
    "    count=0\n",
    "    seq_number = 0\n",
    "    for block in tqdm(blocktrace, desc=\"OPT\"):\n",
    "#    for block in blocktrace: \n",
    "        LFUDict[block] +=1\n",
    "\n",
    "        if len(OPT[block]) is not 0 and OPT[block][0] == seq_number:\n",
    "            OPT[block].popleft()\n",
    "        CacheTS [blocktrace[seq_number]] = timestamp[seq_number]\n",
    "        CachePID [blocktrace[seq_number]] = pid[seq_number]\n",
    "        if block in C:\n",
    "            hit+=1\n",
    "            LRUQ.remove(block)\n",
    "            LRUQ.append(block)\n",
    "            assert( seq_number in D)\n",
    "            del D[seq_number]\n",
    "            if len(OPT[block]) is not 0:\n",
    "                D[OPT[block][0]] = block\n",
    "                OPT[block].popleft()\n",
    "            else:\n",
    "                D[maxpos] = block\n",
    "                maxpos -= 1\n",
    "        else:\n",
    "            miss+=1\n",
    "            if len(C) == frame:\n",
    "                assert(len(D) == frame)\n",
    "                evictpos = max(D)\n",
    "                C.remove(D[evictpos])\n",
    "                LRUQ.remove(D[evictpos])\n",
    "                del CacheTS [D[evictpos]]\n",
    "                del CachePID [D[evictpos]]\n",
    "                del D[evictpos]\n",
    "            if len(OPT[block]) is not 0:\n",
    "                D[OPT[block][0]] = block\n",
    "                OPT[block].popleft()\n",
    "            else:\n",
    "                D[maxpos] = block\n",
    "                maxpos -= 1\n",
    "            C.append(block)\n",
    "            LRUQ.append(block)\n",
    "            if (seq_number % sampling_freq +1 == sampling_freq and len(C) == frame):\n",
    "                Y_OPT = populateData(LFUDict, LRUQ, C, D, CacheTS, CachePID)\n",
    "                lruPredict(C,LRUQ,Y_OPT)\n",
    "                lfuPredict(C,LFUDict,Y_OPT)\n",
    "        seq_number += 1\n",
    "\n",
    "    hitrate = hit / (hit + miss)\n",
    "    print(hitrate)\n",
    "    return hitrate\n",
    "\n",
    "belady_opt(blocktrace, cache_size)\n",
    "\n",
    "print (\"size of X \" + str(len(X)))\n",
    "\n",
    "# round off so that train, test splits are cache size aligned\n",
    "X = X[0:len(X)-(len(X)%(cache_size * 10))]\n",
    "Y = Y[0:len(Y)-(len(Y)%(cache_size * 10))]\n",
    "\n",
    "print (\"Test Y\")\n",
    "\n",
    "for i in range(int(len(X) / 1000)):\n",
    "   y = Y[i*1000:(i+1) *1000]\n",
    "   assert(Counter(y)[1] == eviction)\n",
    "\n",
    "print (\"size of X \" + str(len(X)))\n",
    "print (\"size of Y \" + str(len(Y)))\n",
    "\n",
    "#Train-Test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y ,test_size=0.3, random_state=0, shuffle=False)\n",
    "\n",
    "print (\"Test Y_test\")\n",
    "\n",
    "for i in range(int(len(X_test) / cache_size)):\n",
    "   y = Y_test[i*cache_size:(i+1) *cache_size]\n",
    "   assert(Counter(y)[1] == eviction)\n",
    "\n",
    "print (\"size of X_train \" + str(len(X_train)))\n",
    "print (\"size of X_test \" + str(len(X_test)))\n",
    "\n",
    "#Fitting Logistic Regression Model\n",
    "#logreg = LogisticRegression(solver='lbfgs')\n",
    "#â€˜newton-cgâ€™, â€˜lbfgsâ€™, â€˜liblinearâ€™, â€˜sagâ€™, â€˜sagaâ€™\n",
    "logreg = LogisticRegression(solver='saga')\n",
    "logreg.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = logreg.predict(X_test)\n",
    "print(\"======================================\")\n",
    "print(logreg.predict_proba([X_test[0]]))\n",
    "print(Y_test[0])\n",
    "print(\"=======================================\")\n",
    "#print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, Y_test)))\n",
    "\n",
    "#confusion_matrix = confusion_matrix(Y_test,Y_pred)\n",
    "#print (confusion_matrix)\n",
    "\n",
    "print (logreg.coef_)\n",
    "\n",
    "print (\"LFU Correct / Incorrect Ratio\")\n",
    "total = lfuCorrect + lfuIncorrect\n",
    "print ( lfuCorrect / total )\n",
    "\n",
    "print (\"LRU Correct / Incorrect Ratio\")\n",
    "total = lruCorrect + lruIncorrect\n",
    "print ( lruCorrect / total )\n",
    "\n",
    "c=0\n",
    "\n",
    "logRegIncorrect = 0\n",
    "logRegCorrect = 0\n",
    "\n",
    "for i in range(int(len(X_test)/cache_size)):\n",
    "    Y_pred_prob = logreg.predict_proba(X_test[i*cache_size:(i+1)*cache_size])\n",
    "    Y_pred_current = Y_getMinPredict(Y_pred_prob)\n",
    "    Y_test_current = Y_test[i*cache_size:(i+1)*cache_size]\n",
    "    assert(Counter(Y_test_current)[1] == eviction)\n",
    "    for j in range(len(Y_test_current)):\n",
    "        if np.equal(Y_test_current[j], Y_pred_current[j]):\n",
    "            logRegCorrect +=1\n",
    "        else:\n",
    "            logRegIncorrect +=1\n",
    "\n",
    "print (\"logRegCorrect = \" + str(logRegCorrect))\n",
    "print (\"logRegInorrect = \" + str(logRegIncorrect))\n",
    "print (\"correct = \" + str(logRegCorrect / ( logRegCorrect + logRegIncorrect)))\n",
    "\n",
    "\n",
    "def hitRate(blocktrace, frame):\n",
    "    LFUDict = defaultdict(int)\n",
    "    LRUQ = []\n",
    "    CacheTS = defaultdict(int)\n",
    "    CachePID = defaultdict(int)\n",
    "\n",
    "    hit, miss = 0, 0\n",
    "\n",
    "    C = []\n",
    "    evictCacheIndex = np.array([])\n",
    "    count=0\n",
    "    seq_number = 0\n",
    "    for block in tqdm(blocktrace, desc=\"OPT\"):\n",
    "        LFUDict[block] +=1\n",
    "        CacheTS [blocktrace[seq_number]] = timestamp[seq_number]\n",
    "        CachePID [blocktrace[seq_number]] = pid[seq_number]\n",
    "        if block in C:\n",
    "            hit+=1\n",
    "            #if C.index(block) in evictCacheIndex:\n",
    "            #    np.delete(evictCacheIndex, C.index(block))\n",
    "                \n",
    "            LRUQ.remove(block)\n",
    "            LRUQ.append(block)\n",
    "        else:\n",
    "            evictPos = -1\n",
    "            miss+=1\n",
    "            if len(C) == frame:\n",
    "                if len(evictCacheIndex) == 0: # call eviction candidates\n",
    "                    X_test = getX(LRUQ, LFUDict, C, CacheTS, CachePID)\n",
    "                    Y_pred_prob = logreg.predict_proba(X_test)\n",
    "                    # index of cache blocks that should be removed\n",
    "                    evictCacheIndex = Y_getBlockSeq(Y_pred_prob)\n",
    "\n",
    "                # evict from cache\n",
    "                evictPos = evictCacheIndex[0]\n",
    "                evictBlock = C[evictPos]\n",
    "                LRUQ.remove(evictBlock)\n",
    "                del CacheTS [evictBlock]\n",
    "                del CachePID [evictBlock]\n",
    "            if evictPos is -1:\n",
    "                C.append(block)\n",
    "            else:\n",
    "                C[evictPos] = block\n",
    "                np.delete(evictCacheIndex, 0)\n",
    "            LRUQ.append(block)\n",
    "            CacheTS [blocktrace[seq_number]] = timestamp[seq_number]\n",
    "            CachePID [blocktrace[seq_number]] = pid[seq_number]\n",
    "        seq_number += 1\n",
    "\n",
    "    hitrate = hit / (hit + miss)\n",
    "    print(hitrate)\n",
    "    return hitrate\n",
    "\n",
    "x = blocktrace[-int(0.3 * len(blocktrace)):]\n",
    "\n",
    "belady_opt(x, cache_size)\n",
    "hitRate(x, cache_size)\n",
    "LFU(x, cache_size)\n",
    "# get LFU hit rate.!!!!!\n",
    "# OPT HIT RATE: 0.07700060725633524\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "652710"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"ikki-110108-112108.1.blkparse\"\n",
    "\n",
    "df = pd.read_csv(filename, sep=' ',header = None)\n",
    "df.columns = ['timestamp','pid','pname','blockNo', \\\n",
    "              'blockSize', 'readOrWrite', 'bdMajor', 'bdMinor', 'hash']\n",
    "\n",
    "blocktrace = df['blockNo'].tolist()\n",
    "\n",
    "len(blocktrace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-49-e7a59cc91dcd>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-49-e7a59cc91dcd>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    belady_opt(blocktrace:, cache_size)\u001b[0m\n\u001b[1;37m                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "belady_opt(blocktrace:, cache_size)\n",
    "hitRate(blocktrace, cache_size)\n",
    "LFU(blocktrace, cache_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195813.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "652710*0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
