# -*- coding: utf-8 -*-
"""LogisticRegression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1l05AMYRJSDcPF15W_JpVLExQhihZgs0n

Header Files
"""

import numpy as np
from tqdm import tqdm
#from tqdm import tqdm_notebook as tqdm
import pandas as pd
import numpy as np
from collections import defaultdict
from functools import partial
import matplotlib.pyplot as plt
from matplotlib.pyplot import figure 
import time
import argparse
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.feature_extraction.text import CountVectorizer
#from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import MultiLabelBinarizer
from collections import deque

"""Reading files into a panda data frame."""

df = pd.read_csv('smalltrace.csv', sep='\t')
df.columns = ['no','timestamp','pid','pname','bno', 'bsize', 'op', 'dvmajor', 'dvminor', 'blockhash']

"""The read data frame looks as follows:"""

df.head()

"""Created two lists - one called sequences and the other called blocktrace. 

sequcences stores the sequence number of each I/O operation. block.

blocktrace stores the block numbers that were accessed per I/O operation.
"""

blocktrace = df['bno'].tolist()
seq = df['no'].tolist()
#convert element to int from str
sequences = np.array([int(x) for x in seq])
blocktrace = np.array([int(x) for x in blocktrace])

"""This function gets the relative Time stamp of each element in the cache with respect to 

Input: Cache sequence [1, 2, 3]. get cache blocks by df['bno'][cache sequence #]

  get timestamp
  df['timestamp'][1], df['timestamp'][2], df['timestamp'][3]
  find avg. (avgTS)
  
  get relative => (avgTS - df['timestamp'][A])
  Output: [relativeA, relativeB, relativeC]
"""

def getRelativeTS(Cache_indices):
  tfsm=np.zeros((len(Cache_indices)))
  for i in Cache_indices:
    tfsm [Cache_indices.index(i)] = df.timestamp[i]
  
  avgTS = np.mean(tfsm)
  relTS = avgTS-tfsm
  
  return list(relTS)    
  #df.at[]

"""Input: Input: Cache sequence [1, 2, 3]. 
 
 get cache blocks [A,B,C] by df['bno'][cache sequence #]
 
  gdaAbno df['bno'][1], df['bno'][2], df['bno'][3]
"""

def getRelativePos():
    return 0

'''
get the furthest accessed block. Scans OPT dictionary and selects the maximum positioned element
'''

def getFurthestAccessBlock(C, OPT):
    maxAccessPosition = -1
    maxAccessBlock = -1
    for cached_block in C:
        if len(OPT[cached_block]) is 0:
            #print ( "Not Acccessing block anymore " + str(cached_block))
            return cached_block            
    for cached_block in C:  
        if OPT[cached_block][0] > maxAccessPosition:
            maxAccessPosition = OPT[cached_block][0]
            maxAccessBlock = cached_block
    #print ( "chose to evict " + str(maxAccessBlock) + " since its position of access is " + str(maxAccessPosition))
    return maxAccessBlock

def belady_opt(blocktrace,sequences,frame):
    OPT = defaultdict(partial(np.ndarray,0))

    for i, block in enumerate(tqdm(blocktrace, desc="OPT: building index")):
        OPT[block] = np.append(OPT[block], i)    

    #print ("created OPT dictionary")    

    hit, miss = 0, 0

    C = deque()
    C2 = deque()
    d = defaultdict(deque)
    d_ftime = set()
    d_timestamp = {}
    d_label = {}
    
    for k,block in enumerate(tqdm(blocktrace, desc="OPT", leave=False)):

        if block in C:
            #OPT[block] = OPT[block][1:]
            OPT[block] = np.delete(OPT[block],0)
            hit+=1
            #print('hit' + str(block))
            #print(OPT)
        else:
            #print('miss' + str(block))
            miss+=1
            if len(C) == frame:
                fblock = getFurthestAccessBlock(C, OPT)
                assert(fblock != -1)
                d[fblock] = deque(zip(C,C2)) 
                d_timestamp[fblock] = getRelativeTS(list(C2)) #Returning Time Stemp
                d_label[fblock] = C.index(fblock)
                C2.remove(C2[C.index(fblock)])
                C.remove(fblock)
                #C2.remove()
                d_ftime.add(sequences[k])
            C.append(block)
            C2.append(k)
            d_ftime.add(sequences[k])
            #OPT[block] = OPT[block][1:]
            #print(OPT)
            OPT[block] = np.delete(OPT[block],[0])

    #print ("hit count" + str(hit_count))
    #print ("miss count" + str(miss_count))
    hitrate = hit / (hit + miss)
    print(hitrate)
    return d,d_timestamp,d_label

d,d_timestamp,d_label = belady_opt(blocktrace,sequences, 10)

d[14254312]

d_label[14254312]

len(d_timestamp)

#Time Stamp only (Training data)
data = []
for i,j in d_timestamp.items():
  dat = list(map(str, j))
  data.append(' '.join(dat))
  #label.append(i)
len(data)

#Time Stamp only (Label data)
label = []
for i,j in d_label.items():
  label.append(j)
len(label)

#CountVEctorizer for fitting the data
vec = CountVectorizer(binary=True)
vec_ = vec.fit(data)
DATA = vec_.transform(data)
DATA

#Train-Test split
X_train, X_test, Y_train, Y_test = train_test_split(DATA, label ,test_size=0.2, shuffle=True)

#Fitting Logistic Regression Model
clf = LogisticRegression().fit(X_train, Y_train)

#Accuracy Testing
accuracy_score(Y_test, clf.predict(X_test))



