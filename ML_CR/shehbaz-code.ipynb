{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (4.28.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed 1.21.8 requires msgpack, which is not installed.\n",
      "You are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OPT: building index: 100%|██████████████████████████████████████████████| 1322890/1322890 [00:01<00:00, 1219365.95it/s]\n",
      "OPT: 100%|████████████████████████████████████████████████████████████████| 1322890/1322890 [01:05<00:00, 20223.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0713407766329778\n",
      "size of X 1240000\n",
      "Test Y\n",
      "size of X 1240000\n",
      "size of Y 1240000\n",
      "Test Y_test\n",
      "size of X_train 868000\n",
      "size of X_test 372000\n",
      "0.9191021505376344\n",
      "[[334549    251]\n",
      " [ 29843   7357]]\n",
      "======================================\n",
      "[[0.8922593 0.1077407]]\n",
      "0\n",
      "=======================================\n",
      "[[ 18.49159755  99.01914075 115.37661952]]\n",
      "LFU Correct / Incorrect Ratio\n",
      "0.8572370967741936\n",
      "LRU Correct / Incorrect Ratio\n",
      "0.8166790322580645\n",
      "logRegCorrect = 341204\n",
      "logRegInorrect = 30796\n",
      "correct = 0.9172150537634408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OPT: 100%|████████████████████████████████████████████████████████████████| 1322890/1322890 [00:42<00:00, 30832.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05263249400932806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 396867/396867 [00:31<00:00, 12733.27it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.08011500074332208"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[458]:\n",
    "\n",
    "from tqdm import tqdm as tqdm \n",
    "import numpy as np\n",
    "from collections import deque, defaultdict\n",
    "import timeit\n",
    "import pandas as pd\n",
    "import random\n",
    "from collections import Counter\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import sys\n",
    "\n",
    "# dummy maxmimum position variable. assign the position of blocks that \n",
    "# will never get accessed a value greater than this value. this way OPT\n",
    "# can be fooled to think that the block will be accessed but at a position\n",
    "# far-far-away in time.\n",
    "\n",
    "maxpos = 1000000000000\n",
    "\n",
    "num_params = 3\n",
    "\n",
    "cache_size = 100 # default cache size\n",
    "sampling_freq = cache_size # number of samples skipped\n",
    "eviction = int(0.1 * cache_size)  # number of blocks evicted\n",
    "#filename = \"cheetah.cs.fiu.edu-110108-113008.1.blkparse\"\n",
    "#filename = \"cheetah.1000\"\n",
    "\n",
    "#df = pd.read_csv(filename, sep=' ',header = None)\n",
    "#df.columns = ['timestamp','pid','pname','blockNo', 'blockSize', 'readOrWrite', 'bdMajor', 'bdMinor', 'hash']\n",
    "#df.head()\n",
    "\n",
    "# In[460]:\n",
    "\n",
    "#blocktrace = df['blockNo'].tolist()\n",
    "\n",
    "timestamp = df['timestamp'].tolist()\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "le.fit(df['pid'].tolist())\n",
    "\n",
    "pid = le.transform(df['pid'].tolist())\n",
    "\n",
    "\n",
    "# In[466]:\n",
    "\n",
    "\n",
    "#LRU(blocktrace, 500)\n",
    "\n",
    "\n",
    "# In[467]:\n",
    "\n",
    "\n",
    "def LFU(blocktrace, frame):\n",
    "    \n",
    "    cache = set()\n",
    "    cache_frequency = defaultdict(int)\n",
    "    frequency = defaultdict(int)\n",
    "    \n",
    "    hit, miss = 0, 0\n",
    "    \n",
    "    for block in tqdm(blocktrace):\n",
    "        frequency[block] += 1\n",
    "        \n",
    "        if block in cache:\n",
    "            hit += 1\n",
    "            cache_frequency[block] += 1\n",
    "        \n",
    "        elif len(cache) < frame:\n",
    "            cache.add(block)\n",
    "            cache_frequency[block] += 1\n",
    "            miss += 1\n",
    "\n",
    "        else:\n",
    "            e, f = min(cache_frequency.items(), key=lambda a: a[1])\n",
    "            cache_frequency.pop(e)\n",
    "            cache.remove(e)\n",
    "            cache.add(block)\n",
    "            cache_frequency[block] = frequency[block]\n",
    "            miss += 1\n",
    "    \n",
    "    hitrate = hit / ( hit + miss )\n",
    "    return hitrate\n",
    "\n",
    "'''\n",
    "    given C, use LFUDict to find eviction number of blocks from the Cache\n",
    "    compare it with Y_OPT and store number of places the two differ\n",
    "'''\n",
    "lruCorrect = 0\n",
    "lruIncorrect = 0\n",
    "\n",
    "def lruPredict(C,LRUQ,Y_OPT):\n",
    "    global lruCorrect, lruIncorrect\n",
    "    Y_current = []\n",
    "    KV = defaultdict(int)\n",
    "    for i in range(len(LRUQ)):\n",
    "        KV[LRUQ[i]] = len(LRUQ) - i\n",
    "    KV_sorted = Counter(KV)\n",
    "    evict_dict = dict(KV_sorted.most_common(eviction))\n",
    "    for e in C:\n",
    "        if e in evict_dict:\n",
    "            Y_current.append(1)\n",
    "        else:\n",
    "            Y_current.append(0)\n",
    "    for i in range(len(Y_current)):\n",
    "        if Y_current[i] is Y_OPT[i]:\n",
    "            lruCorrect+=1\n",
    "        else:\n",
    "            lruIncorrect+=1\n",
    "    return Y_current\n",
    "\n",
    "# returns sequence of blocks in prioirty order\n",
    "\n",
    "def Y_getBlockSeq(Y_pred_prob):\n",
    "    x = []\n",
    "    for i in range(len(Y_pred_prob)):\n",
    "        x.append(Y_pred_prob[i][0])\n",
    "    x = np.array(x)\n",
    "    idx = np.argsort(x)\n",
    "    idx = idx[:eviction]\n",
    "    return idx\n",
    "\n",
    "def Y_getMinPredict(Y_pred_prob):\n",
    "    x = []\n",
    "    for i in range(len(Y_pred_prob)):\n",
    "        x.append(Y_pred_prob[i][0])\n",
    "    x = np.array(x)\n",
    "    idx = np.argpartition(x, eviction)\n",
    "    \n",
    "    Y_pred = np.zeros(len(Y_pred_prob), dtype=int)\n",
    "    for i in range(eviction):\n",
    "        Y_pred[idx[i]] = 1\n",
    "    assert(Counter(Y_pred)[1] == eviction)\n",
    "    return Y_pred\n",
    "\n",
    "'''\n",
    "    given C, use LFUDict to find eviction number of blocks from the Cache\n",
    "    compare it with Y_OPT and store number of places the two differ\n",
    "\n",
    "    The number of correct and incorrect predictions with respect to OPT.\n",
    "'''\n",
    "\n",
    "lfuCorrect = 0\n",
    "lfuIncorrect = 0\n",
    "\n",
    "def lfuPredict(C,LFUDict,Y_OPT):\n",
    "    global lfuCorrect, lfuIncorrect\n",
    "    Y_current = []\n",
    "    KV = defaultdict()\n",
    "    for e in C:\n",
    "        KV[e] = LFUDict[e]\n",
    "    KV_sorted = Counter(KV)\n",
    "    evict_dict = dict(KV_sorted.most_common(eviction))\n",
    "    for e in C:\n",
    "        if e in evict_dict:\n",
    "            Y_current.append(1)\n",
    "        else:\n",
    "            Y_current.append(0)\n",
    "    for i in range(len(Y_current)):\n",
    "        if Y_current[i] is Y_OPT[i]:\n",
    "            lfuCorrect+=1\n",
    "        else:\n",
    "            lfuIncorrect+=1\n",
    "    return Y_current\n",
    "\n",
    "# return \"eviction\" blocks that are being accessed furthest\n",
    "# from the cache that was sent to us.\n",
    "\n",
    "def getY(C,D):\n",
    "    assert(len(C) == len(D))\n",
    "    Y_current = []\n",
    "    KV_sorted = Counter(D)\n",
    "    evict_dict = dict(KV_sorted.most_common(eviction))\n",
    "    assert(len(evict_dict) == eviction)\n",
    "    all_vals = evict_dict.values()\n",
    "    for e in C:\n",
    "        if e in evict_dict.values():\n",
    "            Y_current.append(1)\n",
    "        else:\n",
    "            Y_current.append(0)\n",
    "    #print (Y_current.count(1))\n",
    "    assert(Y_current.count(1) == eviction)\n",
    "    assert((set(all_vals)).issubset(set(C)))\n",
    "    return Y_current\n",
    "\n",
    "def getLFURow(LFUDict, C):\n",
    "    x_lfurow = []\n",
    "    for e in C:\n",
    "        x_lfurow.append(LFUDict[e])\n",
    "    norm = x_lfurow / np.linalg.norm(x_lfurow)\n",
    "    return norm\n",
    "    \n",
    "def getLRURow(LRUQ, C):\n",
    "    x_lrurow = []\n",
    "    KV = defaultdict(int)\n",
    "    for i in range(len(LRUQ)):\n",
    "        KV[LRUQ[i]] = i\n",
    "    for e in C:\n",
    "        x_lrurow.append(KV[e])\n",
    "    norm = x_lrurow / np.linalg.norm(x_lrurow)\n",
    "    return norm\n",
    "\n",
    "def normalize(feature, blocks):\n",
    "    x_feature = []\n",
    "    for i in range(len(blocks)):\n",
    "        x_feature.append(feature[blocks[i]])\n",
    "    return x_feature / np.linalg.norm(x_feature)\n",
    "\n",
    "def getX(LRUQ, LFUDict, C, CacheTS, CachePID):\n",
    "    X_lfurow = getLFURow(LFUDict, C)\n",
    "    X_lrurow = getLRURow(LRUQ, C)\n",
    "    X_bno    = C / np.linalg.norm(C)\n",
    "#     X_ts     = normalize(CacheTS, C)\n",
    "#     X_pid    = normalize(CachePID, C)\n",
    "    return (np.column_stack((X_lfurow, X_lrurow, X_bno)))\n",
    "    \n",
    "# appends OPT sample to X, Y arrays\n",
    "\n",
    "X = np.array([], dtype=np.int64).reshape(0,num_params)\n",
    "Y = np.array([], dtype=np.int64).reshape(0,1)\n",
    "\n",
    "# C - cache, LFUDict - dictionary containing block-> access frequency\n",
    "# LRUQ - order of element access in Cache.\n",
    "\n",
    "def populateData(LFUDict, LRUQ, C, D, CacheTS, CachePID):\n",
    "    global X,Y\n",
    "    C = list(C)\n",
    "    Y_current = getY(C, D)\n",
    "    X_current = getX(LRUQ, LFUDict, C, CacheTS, CachePID)\n",
    "\n",
    "    Y = np.append(Y, Y_current)\n",
    "    X = np.concatenate((X,X_current))\n",
    "    assert(Y_current.count(1) == eviction)\n",
    "    return Y_current\n",
    "\n",
    "#D - dictionary for faster max() finding among available blocks\n",
    "#this dictionary contains next_position -> block_number of blocks in Cache\n",
    "#LFUDict - dictionary containing {block -> access_frequencies}\n",
    "#LRUQ - deque of all elements in cache based on recency of access\n",
    "\n",
    "def belady_opt(blocktrace, frame):\n",
    "    global maxpos\n",
    "    OPT = defaultdict(deque)\n",
    "    D = defaultdict(int)\n",
    "    LFUDict = defaultdict(int)\n",
    "    LRUQ = []\n",
    "    CacheTS = defaultdict(int)\n",
    "    CachePID = defaultdict(int)\n",
    "\n",
    "    for i, block in enumerate(tqdm(blocktrace, desc=\"OPT: building index\")):\n",
    "        OPT[block].append(i)\n",
    "\n",
    "    hit, miss = 0, 0\n",
    "\n",
    "    C = []\n",
    "    #count=0\n",
    "    #seq_number = 0\n",
    "    for seq_number, block in enumerate(tqdm(blocktrace, desc=\"OPT\")):\n",
    "#    for block in blocktrace: \n",
    "        LFUDict[block] +=1\n",
    "\n",
    "        if len(OPT[block]) is not 0 and OPT[block][0] == seq_number:\n",
    "            OPT[block].popleft()\n",
    "        CacheTS [blocktrace[seq_number]] = timestamp[seq_number]\n",
    "        CachePID [blocktrace[seq_number]] = pid[seq_number]\n",
    "        if block in C:\n",
    "            hit+=1\n",
    "            LRUQ.remove(block)\n",
    "            LRUQ.append(block)\n",
    "            assert( seq_number in D)\n",
    "            del D[seq_number]\n",
    "            if len(OPT[block]) is not 0:\n",
    "                D[OPT[block][0]] = block\n",
    "                OPT[block].popleft()\n",
    "            else:\n",
    "                D[maxpos] = block\n",
    "                maxpos -= 1\n",
    "        else:\n",
    "            miss+=1\n",
    "            if len(C) == frame:\n",
    "                assert(len(D) == frame)\n",
    "                evictpos = max(D)\n",
    "                \n",
    "                if (seq_number % sampling_freq +1 == sampling_freq):\n",
    "                    Y_OPT = populateData(LFUDict, LRUQ, C, D, CacheTS, CachePID)\n",
    "                    lruPredict(C,LRUQ,Y_OPT)\n",
    "                    lfuPredict(C,LFUDict,Y_OPT)\n",
    "                \n",
    "                C[C.index(D[evictpos])] = block\n",
    "                LRUQ.remove(D[evictpos])\n",
    "                del CacheTS [D[evictpos]]\n",
    "                del CachePID [D[evictpos]]\n",
    "                del D[evictpos]\n",
    "            else:\n",
    "                C.append(block)\n",
    "                \n",
    "            if len(OPT[block]) is not 0:\n",
    "                D[OPT[block][0]] = block\n",
    "                OPT[block].popleft()\n",
    "            else:\n",
    "                D[maxpos] = block\n",
    "                maxpos -= 1\n",
    "            LRUQ.append(block)\n",
    "\n",
    "\n",
    "    hitrate = hit / (hit + miss)\n",
    "    print(hitrate)\n",
    "    return hitrate\n",
    "\n",
    "belady_opt(blocktrace, cache_size)\n",
    "\n",
    "print (\"size of X \" + str(len(X)))\n",
    "\n",
    "# round off so that train, test splits are cache size aligned\n",
    "X = X[0:len(X)-(len(X)%(cache_size * 10))]\n",
    "Y = Y[0:len(Y)-(len(Y)%(cache_size * 10))]\n",
    "\n",
    "print (\"Test Y\")\n",
    "\n",
    "for i in range(int(len(X) / cache_size)):\n",
    "   y = Y[i*cache_size:(i+1) * cache_size]\n",
    "   assert(Counter(y)[1] == eviction)\n",
    "\n",
    "print (\"size of X \" + str(len(X)))\n",
    "print (\"size of Y \" + str(len(Y)))\n",
    "\n",
    "#Train-Test split\n",
    "#X_train, X_test, Y_train, Y_test = train_test_split(X, Y ,test_size=0.3, random_state=0, shuffle=False)\n",
    "X_train = X\n",
    "Y_train = Y\n",
    "\n",
    "# print (\"Test Y_test\")\n",
    "\n",
    "# for i in range(int(len(X_test) / cache_size)):\n",
    "#    y = Y_test[i*cache_size:(i+1) *cache_size]\n",
    "#    assert(Counter(y)[1] == eviction)\n",
    "\n",
    "# print (\"size of X_train \" + str(len(X_train)))\n",
    "# print (\"size of X_test \" + str(len(X_test)))\n",
    "\n",
    "#Fitting Logistic Regression Model\n",
    "#logreg = LogisticRegression(solver='lbfgs')\n",
    "#‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, Y_train)\n",
    "print(logreg.score(X_test, Y_test))\n",
    "print(confusion_matrix(Y_test,logreg.predict(X_test)))\n",
    "Y_pred = logreg.predict(X_test)\n",
    "print(\"======================================\")\n",
    "print(logreg.predict_proba([X_test[0]]))\n",
    "print(Y_test[0])\n",
    "print(\"=======================================\")\n",
    "#print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, Y_test)))\n",
    "\n",
    "#confusion_matrix = confusion_matrix(Y_test,Y_pred)\n",
    "#print (confusion_matrix)\n",
    "\n",
    "print (logreg.coef_)\n",
    "\n",
    "print (\"LFU Correct / Incorrect Ratio\")\n",
    "total = lfuCorrect + lfuIncorrect\n",
    "print ( lfuCorrect / total )\n",
    "\n",
    "print (\"LRU Correct / Incorrect Ratio\")\n",
    "total = lruCorrect + lruIncorrect\n",
    "print ( lruCorrect / total )\n",
    "\n",
    "c=0\n",
    "\n",
    "logRegIncorrect = 0\n",
    "logRegCorrect = 0\n",
    "\n",
    "for i in range(int(len(X_test)/cache_size)):\n",
    "    Y_pred_prob = logreg.predict_proba(X_test[i*cache_size:(i+1)*cache_size])\n",
    "    Y_pred_current = Y_getMinPredict(Y_pred_prob)\n",
    "    Y_test_current = Y_test[i*cache_size:(i+1)*cache_size]\n",
    "    assert(Counter(Y_test_current)[1] == eviction)\n",
    "    for j in range(len(Y_test_current)):\n",
    "        if np.equal(Y_test_current[j], Y_pred_current[j]):\n",
    "            logRegCorrect +=1\n",
    "        else:\n",
    "            logRegIncorrect +=1\n",
    "\n",
    "print (\"logRegCorrect = \" + str(logRegCorrect))\n",
    "print (\"logRegInorrect = \" + str(logRegIncorrect))\n",
    "print (\"correct = \" + str(logRegCorrect / ( logRegCorrect + logRegIncorrect)))\n",
    "\n",
    "def hitRate(blocktrace, frame):\n",
    "    LFUDict = defaultdict(int)\n",
    "    LRUQ = []\n",
    "    CacheTS = defaultdict(int)\n",
    "    CachePID = defaultdict(int)\n",
    "\n",
    "    hit, miss = 0, 0\n",
    "\n",
    "    C = []\n",
    "    evictCacheIndex = np.array([])\n",
    "    #count=0\n",
    "    #seq_number = 0\n",
    "    for seq_number, block in enumerate(tqdm(blocktrace, desc=\"OPT\")):\n",
    "        #print(len(evictCacheIndex))\n",
    "        LFUDict[block] +=1\n",
    "        CacheTS[blocktrace[seq_number]] = timestamp[seq_number]\n",
    "        CachePID[blocktrace[seq_number]] = pid[seq_number]\n",
    "        if block in C:\n",
    "            hit+=1\n",
    "#             if C.index(block) in evictCacheIndex:\n",
    "#                 np.delete(evictCacheIndex, C.index(block))\n",
    "                \n",
    "            LRUQ.remove(block)\n",
    "            LRUQ.append(block)\n",
    "        else:\n",
    "            evictPos = -1\n",
    "            miss+=1\n",
    "            if len(C) == frame:\n",
    "                if len(evictCacheIndex) == 0: # call eviction candidates\n",
    "                    X_test = getX(LRUQ, LFUDict, C, CacheTS, CachePID)\n",
    "                    Y_pred_prob = logreg.predict_proba(X_test)\n",
    "                    # index of cache blocks that should be removed\n",
    "                    evictCacheIndex = Y_getBlockSeq(Y_pred_prob)\n",
    "                    #return Y_pred_prob, evictCacheIndex\n",
    "                # evict from cache\n",
    "                evictPos = evictCacheIndex[0]\n",
    "                evictBlock = C[evictPos]\n",
    "                LRUQ.remove(evictBlock)\n",
    "                del CacheTS [evictBlock]\n",
    "                del CachePID [evictBlock]\n",
    "            if evictPos is -1:\n",
    "                C.append(block)\n",
    "            else:\n",
    "                C[evictPos] = block\n",
    "                evictCacheIndex = np.delete(evictCacheIndex, 0)\n",
    "            LRUQ.append(block)\n",
    "            CacheTS [blocktrace[seq_number]] = timestamp[seq_number]\n",
    "            CachePID [blocktrace[seq_number]] = pid[seq_number]\n",
    "        seq_number += 1\n",
    "\n",
    "    hitrate = hit / (hit + miss)\n",
    "    print(hitrate)\n",
    "    return hitrate\n",
    "\n",
    "x = blocktrace[-int(0.3 * len(blocktrace)):]\n",
    "\n",
    "#belady_opt(x, cache_size)\n",
    "m = hitRate(blocktrace, cache_size)\n",
    "\n",
    "LFU(x, cache_size)\n",
    "# get LFU hit rate.!!!!!\n",
    "# OPT HIT RATE: 0.07700060725633524"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 1322890/1322890 [01:46<00:00, 12453.61it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.05411561051939315"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFU(blocktrace, cache_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23374516"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"DATA/cheetah.cs.fiu.edu-110108-113008.3.blkparse\"\n",
    "\n",
    "df = pd.read_csv(filename, sep=' ',header = None)\n",
    "df.columns = ['timestamp','pid','pname','blockNo', \\\n",
    "              'blockSize', 'readOrWrite', 'bdMajor', 'bdMinor', 'hash']\n",
    "\n",
    "blocktrace = df['blockNo'].tolist()\n",
    "\n",
    "len(blocktrace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
